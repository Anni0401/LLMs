{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API Key loaded successfully\n",
      "Tavily API Key loading failed, please make sure the .env file exists and the spelling is correct\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if os.getenv(\"GROQ_API_KEY\"):\n",
    "    print('Groq API Key loaded successfully')\n",
    "else:\n",
    "    print('Groq API Key loading failed, please make sure the .env file exists and the spelling is correct')\n",
    "\n",
    "if os.getenv(\"TAVILY_API_KEY\"):\n",
    "    print('Tavily API Key loaded successfully')\n",
    "else:\n",
    "    print('Tavily API Key loading failed, please make sure the .env file exists and the spelling is correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_groq import ChatGroq\n",
    "import random\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for Game Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, board_id):\n",
    "        self.board = self.initialize_board(board_id)\n",
    "        self.red_words = [key for key, value in self.board.items() if value == \"red\"]\n",
    "        self.blue_words = [key for key, value in self.board.items() if value == \"blue\"]\n",
    "        self.black_words = [key for key, value in self.board.items() if value == \"black\"]\n",
    "        self.neutral_word = [key for key, value in self.board.items() if value == \"neutral\"]\n",
    "        self.has_turn = \"RED\"\n",
    "        self.winner = None\n",
    "        self.last_spymaster_answer = None\n",
    "        self.rounds = 0\n",
    "        self.guessed_words = set()\n",
    "        self.max_guesses = 1 # number of words to guess. Updated at every new spymaster clue\n",
    "        self.current_guess_counter = 0\n",
    "        self.right_guesses = 0\n",
    "        self.opponent_guesses = 0\n",
    "        self.neutral_guesses = 0\n",
    "        self.invalid_guesses = 0\n",
    "        self.black_guesses = 0\n",
    "        self.export = {'red':[], 'blue':[]}\n",
    "    \n",
    "        self.current_turn = None\n",
    "\n",
    "    def initialize_board(self, board_id):\n",
    "        if board_id == \"baseline\":\n",
    "            # hardcoded board for baseline\n",
    "            board = {'OIL': 'red', \n",
    "                     'IVORY': 'red', \n",
    "                     'STADIUM': 'blue', \n",
    "                     'BOOM': 'neutral', \n",
    "                     'TAIL': 'blue', \n",
    "                     'BOMB': 'black', \n",
    "                     'GROUND': 'neutral', \n",
    "                     'COMPOUND': 'blue', \n",
    "                     'KID': 'red', \n",
    "                     'CLOAK': 'blue', \n",
    "                     'SKYSCRAPER': 'blue', \n",
    "                     'BLOCK': 'blue', \n",
    "                     'GENIUS': 'red', \n",
    "                     'IRON': 'red', \n",
    "                     'RULER': 'neutral', \n",
    "                     'WORM': 'red', \n",
    "                     'SHARK': 'neutral', \n",
    "                     'FLY': 'red', \n",
    "                     'PILOT': 'blue', \n",
    "                     'OLYMPUS': 'neutral', \n",
    "                     'KETCHUP': 'blue', \n",
    "                     'THIEF': 'neutral', \n",
    "                     'ICE CREAM': 'red', \n",
    "                     'CAR': 'neutral', \n",
    "                     'LAWYER': 'red'}\n",
    "        else:\n",
    "            word_list = self.load_words()\n",
    "            random.seed(int(board_id))\n",
    "            board_words = random.sample(word_list, 25)\n",
    "            colors = [\"red\"] * 9 + [\"blue\"] * 8 + [\"neutral\"] * 7 + [\"black\"] * 1\n",
    "            random.shuffle(colors)\n",
    "            board = dict(zip(board_words, colors))\n",
    "        return board\n",
    "    \n",
    "    def load_words(self):\n",
    "        with open('wordlist-eng.txt', 'r') as file:\n",
    "            words = [line.strip() for line in file]\n",
    "            return words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for Game History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class History():\n",
    "    def __init__(self,board): \n",
    "        self.board = board\n",
    "        self.history = []\n",
    "        self.winner = None\n",
    "        \n",
    "    def add_round(self, team, clue, number):\n",
    "        self.history.append(\n",
    "            {\n",
    "            \"team\" : team,\n",
    "            \"spymaster_clue\" : clue,\n",
    "            \"number\" : number,\n",
    "            \"actions\" : []\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def add_guesser_action(self, teammember, tool_call, tool_args, tool_return, outcome=None):     \n",
    "        # add action\n",
    "        action = {\n",
    "            \"teammember\" : teammember,\n",
    "            \"tool_call\" : tool_call,\n",
    "            \"tool_args\" : tool_args,\n",
    "            \"tool_return\" : tool_return\n",
    "        }\n",
    "        if outcome is not None:\n",
    "            action[\"outcome\"] = outcome\n",
    "        self.history[-1][\"actions\"].append(action)\n",
    "\n",
    "    def set_winner(self, winner):\n",
    "        self.winner = winner\n",
    "\n",
    "    def save(self, filename):\n",
    "        output = {\n",
    "            \"board\" : self.board,\n",
    "            \"history\" : self.history,\n",
    "            \"winner\" : self.winner\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(output, file)\n",
    "\n",
    "    # def print_stats(self):\n",
    "    #     print(\" STATS \".center(50, \"-\"))\n",
    "    #     print(\"Guesses per category:\")\n",
    "    #     print(self._getNumberOfGuessesPerCategory())\n",
    "\n",
    "    # def _getNumberOfGuessesPerCategory(self):\n",
    "    #     guesses = {\n",
    "    #         \"RED\":{},\n",
    "    #         \"BLUE\":{}\n",
    "    #     }\n",
    "    #     for round in self.history:\n",
    "    #         for turn in round['guesser_turns']:\n",
    "    #             if turn['decision'] == 'guess':\n",
    "    #                 if turn['outcome'] not in guesses[round[\"team\"]].keys():\n",
    "    #                     guesses[round[\"team\"]][turn['outcome']] = 0\n",
    "    #                 guesses[round[\"team\"]][turn['outcome']] += 1\n",
    "    #     return guesses\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain.pydantic_v1 import BaseModel, Field, PrivateAttr\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "\n",
    "class GuessInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a single word from the game-board\")\n",
    "\n",
    "class GuessTool(BaseTool):\n",
    "    name: str = \"codenames_guess_tool\"\n",
    "    description: str = \"essential to guess words from the game-board\"\n",
    "    args_schema: Type[BaseModel] = GuessInput\n",
    "    game: Game = PrivateAttr()\n",
    "\n",
    "    def __init__(self, game):\n",
    "        super().__init__()\n",
    "        # Store the game object as an instance variable\n",
    "        self.game = game\n",
    "\n",
    "    def __call__(self, query: str) -> str:\n",
    "        \"\"\"Allows the tool to be callable directly.\"\"\"\n",
    "        return self._run(query)\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool with context from the game object.\"\"\"\n",
    "        query = query.upper()\n",
    "        if query in self.game.board.keys() and query not in self.game.guessed_words:\n",
    "            self.game.guessed_words.add(query)\n",
    "            return self.game.board[query]\n",
    "        else:\n",
    "            return f\"WRONG: {query}\"\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously with context from the game object.\"\"\"\n",
    "        raise NotImplementedError(\"custom_game_tool does not support async\")\n",
    "    \n",
    "\n",
    "class DiscussInput(BaseModel):\n",
    "    query: str = Field(description=\"should be the message for the teammembers\")\n",
    "\n",
    "class DiscussTool(BaseTool):\n",
    "    name: str = \"codenames_discuss_tool\"\n",
    "    description: str = \"essential to communicate with your teammembers\"\n",
    "    args_schema: Type[BaseModel] = DiscussInput\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, query: str) -> str:\n",
    "        \"\"\"Allows the tool to be callable directly.\"\"\"\n",
    "        return self._run(query)\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool to communicate with your teammembers, the query is the message.\"\"\"\n",
    "        return query    \n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously with context from the game object.\"\"\"\n",
    "        raise NotImplementedError(\"custom_game_tool does not support async\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "class EndTurnTool(BaseTool):\n",
    "    name: str = \"codenames_end_turn_tool\"\n",
    "    description: str = \"essential to end turn before spending all available guesses, for high uncertainty and risk mitigation\"\n",
    "    args_schema: Type[BaseModel] = None\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, query=\"\") -> str:\n",
    "        \"\"\"Allows the tool to be callable directly.\"\"\"\n",
    "        return self._run(query)\n",
    "\n",
    "    def _run(\n",
    "        self, query, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool to end your turn if you have guessed all words with a obvious relation to the clue\"\"\"\n",
    "        if query:\n",
    "            return query\n",
    "        else:\n",
    "            return \"Has ended turn preemptively.\"    \n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously with context from the game object.\"\"\"\n",
    "        raise NotImplementedError(\"custom_game_tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, models: dict[str, dict[str, ChatGroq]], game: Game, api_key:str, tools=None, max_rounds=1):\n",
    "        self.game = game\n",
    "        self.models = models\n",
    "        self.last_message_id = None\n",
    "        self.max_rounds = max_rounds\n",
    "        self.end_turn = False\n",
    "        self.current_guesser_red = 1\n",
    "        self.current_guesser_blue = 1\n",
    "        self.invalid_tool_call = False\n",
    "        self.last_teammember_prompt = None\n",
    "        self.last_teammember_output = None\n",
    "        self.history = History(self.game.board)\n",
    "\n",
    "        graph = StateGraph(AgentState)\n",
    "\n",
    "        # Setting up the nodes for the state graph\n",
    "        graph.add_node(\"spymaster_red\", self.call_red_spymaster)\n",
    "        graph.add_node(\"spymaster_blue\", self.call_blue_spymaster)\n",
    "        graph.add_node(\"teammember_red\", self.call_red_guesser)\n",
    "        graph.add_node(\"teammember_blue\", self.call_blue_guesser)\n",
    "        graph.add_node(\"action_red\", self.take_action)\n",
    "        graph.add_node(\"action_blue\", self.take_action)\n",
    "\n",
    "        # Conditional edges based on game state\n",
    "        graph.add_conditional_edges(\n",
    "             \"action_blue\",\n",
    "             self.define_next_player,\n",
    "             {0: END, 1: \"spymaster_red\", 2: \"teammember_blue\"}\n",
    "        )\n",
    "        graph.add_conditional_edges(\n",
    "             \"action_red\",\n",
    "             self.define_next_player,\n",
    "             {0: END, 1: \"spymaster_blue\", 2: \"teammember_red\"}\n",
    "        )\n",
    "\n",
    "        # Add edges for turn transitions\n",
    "        graph.add_edge(\"spymaster_red\", \"teammember_red\")\n",
    "        graph.add_edge(\"spymaster_blue\", \"teammember_blue\")\n",
    "        graph.set_entry_point(\"spymaster_red\")\n",
    "\n",
    "        # Conditional edges that check for presence of tool call otherwise invoke next team member (see this as a fail safe)\n",
    "        graph.add_conditional_edges(\n",
    "            \"teammember_red\",\n",
    "            self.exists_tool_call,\n",
    "            {True: \"action_red\", False: \"teammember_red\"}\n",
    "        )\n",
    "        graph.add_conditional_edges(\n",
    "            \"teammember_blue\",\n",
    "            self.exists_tool_call,\n",
    "            {True: \"action_blue\", False: \"teammember_blue\"}\n",
    "        )\n",
    "        \n",
    "        # Compile graph to LangChain Runnable\n",
    "        self.graph = graph.compile()\n",
    "\n",
    "        # add LLM to models\n",
    "        for player_type, player_list in self.models.items():\n",
    "            if \"spymaster\" in player_type:\n",
    "                for spymaster in player_list:\n",
    "                    spymaster[\"model\"] = ChatGroq(\n",
    "                        model=\"llama-3.1-70b-versatile\",\n",
    "                        temperature=0.0,\n",
    "                        max_tokens=20,\n",
    "                        timeout=None,\n",
    "                        max_retries=2,\n",
    "                        api_key=api_key\n",
    "                        )\n",
    "\n",
    "            elif \"teammember\" in player_type:\n",
    "                for teammember in player_list:\n",
    "                    teammember[\"model\"] = ChatGroq(\n",
    "                        model=\"llama-3.1-70b-versatile\",\n",
    "                        temperature=0.0,\n",
    "                        max_tokens=None,\n",
    "                        timeout=None,\n",
    "                        max_retries=2,\n",
    "                        api_key=api_key\n",
    "                        )\n",
    "                \n",
    "        # Bind tools to team member models\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        for player_type, player_list in self.models.items():\n",
    "            if \"teammember\" in player_type:\n",
    "                for teammember in player_list:\n",
    "                    teammember[\"model\"] = teammember[\"model\"].bind_tools(tools)\n",
    "\n",
    "\n",
    "    def define_next_player(self, state: AgentState):\n",
    "        exists_guess = self.exists_guess(state)\n",
    "        game_end = self.check_game_end(state)\n",
    "        if game_end:\n",
    "            return 0\n",
    "        elif exists_guess and (self.game.current_guess_counter >= self.game.max_guesses or self.end_turn):\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "    def exists_guess(self, state: AgentState):\n",
    "        last_tool_messages = []\n",
    "        messages = state['messages']\n",
    "        index = len(messages) - 1\n",
    "\n",
    "        while index >= 0:\n",
    "            message = messages[index]\n",
    "            if isinstance(message, ToolMessage):\n",
    "                last_tool_messages.append(message)\n",
    "            else:\n",
    "                # Stop if we encounter a non-ToolMessage type\n",
    "                break\n",
    "            index -= 1\n",
    "        was_guessed = any(m.name == \"codenames_guess_tool\" for m in last_tool_messages)\n",
    "        return was_guessed\n",
    "    \n",
    "    def exists_tool_call(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        print(f\"Test:{result}\")\n",
    "        exists_tool_call = len(result.tool_calls) > 0\n",
    "        if not exists_tool_call:\n",
    "            self.invalid_tool_call = True\n",
    "        return exists_tool_call\n",
    "\n",
    "            \n",
    "    def call_red_spymaster(self, state: AgentState):\n",
    "        return self._call_spymaster(\"RED\", state)\n",
    "\n",
    "    def call_blue_spymaster(self, state: AgentState):\n",
    "        return self._call_spymaster(\"BLUE\", state)\n",
    "\n",
    "    def call_red_guesser(self, state: AgentState):\n",
    "        #number = random.randint(1,self.team_size)\n",
    "        if not self.invalid_tool_call:\n",
    "            # go to next player\n",
    "            self.current_guesser_red = (self.current_guesser_red % len(self.models[\"teammembers_RED\"]))+ 1\n",
    "\n",
    "        return self._call_guesser(\"RED\", self.current_guesser_red, state)\n",
    "\n",
    "    def call_blue_guesser(self, state: AgentState):\n",
    "        #number = random.randint(1,self.team_size)\n",
    "        if not self.invalid_tool_call:\n",
    "            # go to next player\n",
    "            self.current_guesser_blue = (self.current_guesser_blue % len(self.models[\"teammembers_BLUE\"]))+ 1\n",
    "\n",
    "        return self._call_guesser(\"BLUE\", self.current_guesser_blue, state)\n",
    "    \n",
    "    def check_game_end(self, state: AgentState):\n",
    "        game_over = False\n",
    "        if self.game.rounds > self.max_rounds:\n",
    "            game_over = True\n",
    "        game_ends_black = any(word in self.game.guessed_words for word in self.game.black_words)\n",
    "        game_ends_red = all(word in self.game.guessed_words for word in self.game.red_words)\n",
    "        game_ends_blue = all(word in self.game.guessed_words for word in self.game.blue_words)\n",
    "        if game_ends_black or game_ends_red or game_ends_blue:\n",
    "            game_over = True\n",
    "        if game_ends_black:\n",
    "            self.game.winner = \"BLUE\" if self.game.has_turn == \"RED\" else \"RED\"\n",
    "        elif game_ends_red:\n",
    "            self.game.winner = \"RED\"\n",
    "        elif game_ends_blue:\n",
    "            self.game.winner = \"BLUE\"\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        if game_over:\n",
    "            self.history.set_winner(self.game.winner)\n",
    "            print(f\"guessed_words: {', '.join(self.game.guessed_words)}\")\n",
    "            print(f\"WINNER: {self.game.winner}\")\n",
    "            print(f\"ROUNDS PLAYED: {self.game.rounds}\")\n",
    "            \n",
    "\n",
    "\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state.get('messages', [])[-1].tool_calls\n",
    "        results = []\n",
    "        all_calls_invalid = True        \n",
    "        for t in tool_calls:\n",
    "            if t[\"name\"]=='codenames_guess_tool':\n",
    "                all_calls_invalid = False\n",
    "                self.game.current_guess_counter += 1\n",
    "                if self.game.current_guess_counter >= self.game.max_guesses:\n",
    "                    # end turn after this turn\n",
    "                    # this guess can still be taken\n",
    "                    self.end_turn = True\n",
    "                \n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "                guessed_word_color = result.lower()\n",
    "                results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result))) \n",
    "\n",
    "                # Check the result to determine if the turn should end\n",
    "                if guessed_word_color == self.game.has_turn.lower():\n",
    "                    # Correct guess, team can continue if max_guesses not reached\n",
    "                    self.game.right_guesses  = self.game.right_guesses +1\n",
    "                    print(f\"Correct! {t['args']} belongs to team {guessed_word_color}.\")\n",
    "                    # for export\n",
    "                    isCorrect = \"correct\"\n",
    "                elif guessed_word_color == \"black\":\n",
    "                    #End game, other team wins\n",
    "                    self.game.black_guesses = self.game.black_guesses +1\n",
    "                    print(f\"Black word guessed! {self.game.has_turn} loses.\")\n",
    "                    self.end_turn = True\n",
    "                    # for export\n",
    "                    isCorrect = \"incorrect - black\"\n",
    "                elif guessed_word_color == \"neutral\":\n",
    "                    # Neutral word, end turn\n",
    "                    self.game.neutral_guesses = self.game.neutral_guesses +1\n",
    "                    self.end_turn = True\n",
    "                    print(f\"Incorrect! {t['args']} is a {guessed_word_color} word.\")\n",
    "                    # for export\n",
    "                    isCorrect = \"incorrect - neutral\"\n",
    "                elif guessed_word_color == 'red' or guessed_word_color == 'blue':\n",
    "                    # Opponent's word, end turn\n",
    "                    self.game.opponent_guesses = self.game.opponent_guesses +1\n",
    "                    self.end_turn = True\n",
    "                    print(f\"Incorrect! {t['args']} is a {guessed_word_color} word.\")\n",
    "                    # for export\n",
    "                    isCorrect = \"incorrect - opponent\"\n",
    "                else:\n",
    "                    isCorrect = \"incorrect - invalid guess\"\n",
    "                    print(f\"Incorrect! {t['args']} is a invalid word.\")\n",
    "                    self.game.invalid_guesses = self.game.invalid_guesses +1\n",
    "                    self.end_turn = True\n",
    "\n",
    "                # Export\n",
    "                if len(self.game.export[self.game.has_turn.lower()]) == self.game.rounds:\n",
    "                    self.game.export[self.game.has_turn.lower()][-1]['guesses'].append((t[\"args\"]['query'],isCorrect))\n",
    "                else:\n",
    "                    self.game.export[self.game.has_turn.lower()].append(\n",
    "                        {\n",
    "                            'clue':self.game.last_spymaster_answer.content, \n",
    "                            'guesses':[(t[\"args\"]['query'],isCorrect)]\n",
    "                        }\n",
    "                    )\n",
    "                self.history.add_guesser_action(f\"guesser_{self.game.has_turn}_{self.current_guesser_blue}\", t['name'], t['args'], result, outcome=isCorrect)\n",
    "\n",
    "                # End the turn if this was decided\n",
    "                if self.end_turn:\n",
    "                    break\n",
    "                \n",
    "            elif t[\"name\"] == 'codenames_discuss_tool':\n",
    "                all_calls_invalid = False\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "                results.append(ToolMessage(id=self.last_message_id, tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "                self.history.add_guesser_action(f\"guesser_{self.game.has_turn}_{self.current_guesser_blue}\", t['name'], t['args'], result)\n",
    "            elif t[\"name\"]=='codenames_end_turn_tool':\n",
    "                all_calls_invalid = False\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "                results.append(ToolMessage(id=self.last_message_id, tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "                self.end_turn = True\n",
    "                self.history.add_guesser_action(f\"guesser_{self.game.has_turn}_{self.current_guesser_blue}\", t['name'], t['args'], result)\n",
    "            else:\n",
    "                results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=\"Invalid tool name, retry\"))\n",
    "                self.history.add_guesser_action(f\"guesser_{self.game.has_turn}_{self.current_guesser_blue}\", t['name'], t['args'], \"Invalid tool name, retry\")\n",
    "        if all_calls_invalid:\n",
    "            self.invalid_tool_call = True\n",
    "        return {'messages': results}\n",
    "    \n",
    "    def _call_spymaster(self, team, state):\n",
    "        print(' -'*30)\n",
    "        # increase round counter only when red is spymaster (as red starts the game and therefore each round) \n",
    "        if team.lower() == 'red':\n",
    "            self.game.rounds += 1\n",
    "        self.game.current_guess_counter = 0\n",
    "        self.end_turn = False\n",
    "        self.game.has_turn = team.upper()\n",
    "        round = self.game.rounds\n",
    "        messages = state['messages']\n",
    "        prompt = self.get_spymaster_prompt(team)\n",
    "        model = self.models[f\"spymaster_{team}\"][0][\"model\"]\n",
    "        message = model.invoke(prompt)\n",
    "        message.id = f\"{round}_spymaster_{team}\"\n",
    "        # Parse the hint number from the spymaster's message (assuming format \"Word N\")\n",
    "        hint_text = message.content.split()\n",
    "        self.game.max_guesses = int(hint_text[1]) if len(hint_text) > 1 and hint_text[1].isdigit() else 1\n",
    "        #state['messages'].append(message)\n",
    "        self.game.last_spymaster_answer = message\n",
    "        self.game.current_turn = f\"{round}_spymaster_{team}\"\n",
    "        print(f\"{self.game.current_turn} hint: {self.game.last_spymaster_answer.content}\")\n",
    "        # Export\n",
    "        self.history.add_round(team, hint_text[0], self.game.max_guesses)\n",
    "        return {'messages': [message]}\n",
    "    \n",
    "    def _call_guesser(self, team, number, state):\n",
    "        print(' -'*30)\n",
    "\n",
    "        round = self.game.rounds\n",
    "        messages = state['messages']\n",
    "        prompt = self.get_guesser_prompt(team, number)[0].content\n",
    "        new_prompt_content = \"\"\n",
    "        filtered_messages = [m for m in messages if m.id is not None and m.id.startswith(f\"{round}_teammember_{team}\")]\n",
    "        current_discussion_string = \"\\n\".join(f\"{m.id[2:]} said: '{m.content.strip()}'\" for m in filtered_messages if m.id is not None)\n",
    "        if current_discussion_string == \"\":\n",
    "            current_discussion_string = \"No discussion has taken place yet.\"\n",
    "\n",
    "        if self.invalid_tool_call:\n",
    "            invalid_tool_call = \"WARNING: INVALID TOOL CALL WAS JUST MADE! TRY AGAIN AND USE THE PROVIDED TOOLS CORRECTLY\"\n",
    "            new_prompt_content = (\n",
    "                invalid_tool_call\n",
    "                + \"\\n\"\n",
    "                + \"THE LAST PROMPT: \"\n",
    "                + self.last_teammember_prompt\n",
    "                )\n",
    "            self.invalid_tool_call = False\n",
    "        else:\n",
    "            # Retrieve spymaster's hint and prepare discussion string\n",
    "            spymaster_message = self.get_message_by_id(messages, f\"{round}_spymaster_{team}\")\n",
    "            spymaster_hint = f\"Spymaster's hint: {spymaster_message if spymaster_message else 'No hint available'} \\n\"\n",
    "            \n",
    "            #Retrieve info who is in the lead\n",
    "            words_left_red = sum(word not in self.game.guessed_words for word in self.game.red_words)\n",
    "            words_left_blue = sum(word not in self.game.guessed_words for word in self.game.blue_words)\n",
    "\n",
    "\n",
    "            if words_left_red > words_left_blue:\n",
    "                leader_info = \"Team Blue is in the lead\" if team.lower() == 'red' else \"Your Team is in the lead\"\n",
    "            elif words_left_red == words_left_blue:\n",
    "                leader_info = \"Both teams have guessed the same amount of correct words so far\"\n",
    "            else:\n",
    "                leader_info = \"Team Red is in the lead\" if team.lower() == 'blue' else \"Your Team is in the lead\"\n",
    "\n",
    "            leader_info += f\". Team Red has {words_left_red} words left to guess, and Team Blue has {words_left_blue} words left to guess.\"\n",
    "\n",
    "            team_members = [f\"teammember_{team}_{i + 1}\" for i in range(len(self.models[f\"teammembers_{team}\"]))]\n",
    "            team_members.remove(f\"teammember_{team}_{number}\")\n",
    "            team_members_string = f\"Your team members are: {', '.join(team_members)}.\"\n",
    "            you_string = f\"You are teammember_{team}_{number}.\"\n",
    "            self.last_message_id = f\"{round}_teammember_{team}_{number}\"\n",
    "\n",
    "            guesses_this_round = self.game.export[team.lower()][-1]['guesses'] if len(self.game.export[team.lower()]) == round else []\n",
    "\n",
    "            #Combine into new_prompt\n",
    "            current_discussion_string = current_discussion_string.replace(f\"teammember_{team}_{number} said:\", \"You said:\")\n",
    "            new_prompt_content = (\n",
    "                prompt\n",
    "                + \"\\n\"\n",
    "                + spymaster_hint\n",
    "                + f\"With this hint, these guesses were made: {guesses_this_round}\\n\"\n",
    "                + leader_info\n",
    "                + you_string + \"\\n\"\n",
    "                + team_members_string + \"\\n\"\n",
    "                + f\"\\nThis is the current discussion with your Teammembers:\"\n",
    "                + \"\\n\"\n",
    "                + current_discussion_string\n",
    "            )\n",
    "        self.last_teammember_prompt = new_prompt_content\n",
    "\n",
    "        model = self.models[f\"teammembers_{team}\"][number-1][\"model\"]\n",
    "        message = model.invoke([new_prompt_content])  # Pass as a single-item list containing the BaseMessage instance\n",
    "        \n",
    "        # Set message ID and append\n",
    "        #message.id = f\"{round}_teammember_{team}_{number}\"\n",
    "        #state['messages'].append(message)\n",
    "        print(f\"GuessID: {round}_teammember_{team}_{number}\")\n",
    "        print(f\"Current Discussion: \\n {current_discussion_string}\")\n",
    "        print(f\"Answer: \\n {message.content}\")  # Display prompt content for verification\n",
    "        self.last_teammember_output = message.content\n",
    "        return {'messages': [message]}\n",
    "        \n",
    "    def get_spymaster_prompt(self, team):\n",
    "        not_guessed_board = {k: v for k, v in self.game.board.items() if k not in self.game.guessed_words}\n",
    "        relevant_words = [k for k, v in not_guessed_board.items() if v.lower() == team.lower()]\n",
    "        bad_words = [k for k, v in not_guessed_board.items() if v.lower() != team.lower()]\n",
    "        \n",
    "        return [SystemMessage(content=self.models[f\"spymaster_{team}\"][0][\"system\"]\n",
    "            + f\"\\nGood words: {', '.join(relevant_words)}\\n\"\n",
    "            + f\"Bad words: {', '.join(bad_words)}\"\n",
    "        )]\n",
    "    \n",
    "    def get_guesser_prompt(self, team, number):\n",
    "        not_guessed_board = [k for k in self.game.board if k not in self.game.guessed_words]\n",
    "        hint_word = self.game.last_spymaster_answer.content\n",
    "\n",
    "        return [SystemMessage(content=self.models[f\"teammembers_{team}\"][number-1][\"system\"]\n",
    "            + f\"\\nWord list: {', '.join(not_guessed_board)}\\n\"\n",
    "        )]\n",
    "    \n",
    "    def get_message_by_id(self, messages, target_id):\n",
    "        for message in messages:\n",
    "            if message.id == target_id:\n",
    "                return message.content\n",
    "        return None  # Return None if no message with the given id is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompt_from_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        prompt = file.read()  # Reads the entire content of the file as a string\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Games in loop for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series of Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game_Series():\n",
    "    def __init__(self, models, run_name, max_rounds=15, recovery_run=False, board_random_states=range(10), wordlist='wordlist-eng.txt', run_baseline_board=True, save_graph=True):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        models : dict\n",
    "            Dictionary with the models for the agents.\n",
    "        run_name : str\n",
    "            Name of the run. Used to save the output files.\n",
    "        max_rounds : int, optional\n",
    "            Maximum number of rounds per game. \n",
    "        recovery_run : bool, optional\n",
    "            Set to True if you want to continue a previous run (and the output folder already exists). \n",
    "        board_random_states : list, optional\n",
    "            Provide an empty list if you want to run the baseline board only. Else range() with the number of boards you want to run.\n",
    "        wordlist : str, optional\n",
    "            Path to the wordlist file. \n",
    "        run_baseline_board : bool, optional\n",
    "            If True, the baseline board will be evaluated.\n",
    "        save_graph : bool, optional\n",
    "            If True, the graph will be saved as a png file.\n",
    "        \"\"\"\n",
    "\n",
    "        self.models = models\n",
    "        self.run_name = run_name\n",
    "        self.recovery_run = recovery_run\n",
    "        # change all random states to strings for comparison\n",
    "        board_random_states = [str(state) for state in board_random_states]\n",
    "        if run_baseline_board:\n",
    "            self.board_random_states = [\"baseline\"] + list(board_random_states)\n",
    "        self.current_api_id = 0\n",
    "        self.max_rounds = max_rounds\n",
    "\n",
    "        # load api keys\n",
    "        with open(\"api_keys.json\", \"r\") as f:\n",
    "            self.api_keys = json.load(f)\n",
    "        \n",
    "        # recovery run can be used if previous run was interrupted\n",
    "        if self.recovery_run:\n",
    "            # check if folder already exists\n",
    "            if not os.path.exists(f\"output_{self.run_name}\"):\n",
    "                raise Exception(f\"Folder output_{self.run_name} does not exist. Please run a non-recovery run or change the run_name.\")\n",
    "            else:\n",
    "                # get finished game numbers\n",
    "                finished_games = [file.split(\"_\")[-1].split(\".\")[0] for file in os.listdir(f\"output_{self.run_name}\")]\n",
    "                # remove finished games from board_random_states\n",
    "                self.board_random_states = [state for state in self.board_random_states if state not in finished_games]\n",
    "        else:\n",
    "            # check if folder already exists\n",
    "            if os.path.exists(f\"output_{self.run_name}\"):\n",
    "                raise Exception(f\"Folder output_{self.run_name} already exists. Please run a recovery run if you want to continue from there.\")\n",
    "            else:\n",
    "                os.mkdir(f\"output_{self.run_name}\")\n",
    "\n",
    "        if save_graph:\n",
    "            self.save_graph()\n",
    "\n",
    "\n",
    "    def run_series(self):\n",
    "        for board_id in self.board_random_states:\n",
    "            # print new board id centered in 50 dashes\n",
    "            print(f\"{' BOARD ID: ' + str(board_id) + ' '}\".center(50, \"#\"))\n",
    "            self.run_1_round(board_id)\n",
    "        self.combine_results()\n",
    "        self.calculate_statistics()\n",
    "            \n",
    "    def run_1_round(self, board_id):\n",
    "        for i in range(self.current_api_id, len(self.api_keys)):\n",
    "            try:\n",
    "                game = Game(board_id)\n",
    "                abot = Agent(self.models, game, self.api_keys[i], tools=[GuessTool(game),DiscussTool(),EndTurnTool()], max_rounds=self.max_rounds)\n",
    "                messages = [HumanMessage(content=\"Play a game of Codenames.\")]\n",
    "                result = abot.graph.invoke({\"messages\": messages}, {\"recursion_limit\": 200})\n",
    "                self.current_api_id = i\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if i == len(self.api_keys)-1:\n",
    "                    raise Exception(f\"Last API Key failed with error {e}. Please check the error and try again.\")\n",
    "                # wait 10 seconds to prevent too many request\n",
    "                time.sleep(10)\n",
    "                print(f\"API Key {i} failed with error: {e}. Switching to next API Key in 10 seconds.\")\n",
    "                continue\n",
    "\n",
    "        # save game history\n",
    "        abot.history.save(f\"output_{self.run_name}/history_game_{board_id}.json\")\n",
    "            \n",
    "    def combine_results(self):\n",
    "        all_results = []\n",
    "        # get all results\n",
    "        for file in os.listdir(f\"output_{self.run_name}\"):\n",
    "            if \"graph\" in file:\n",
    "                continue\n",
    "            if \"all_results\" in file:\n",
    "                raise Exception(\"all_results.json already exists. Please delete it before running this function.\")\n",
    "            with open(f\"output_{self.run_name}/{file}\", 'r') as f:\n",
    "                data = json.load(f)\n",
    "                data['config'] = self.run_name\n",
    "                data['board_id'] = file.split(\"_\")[-1].split(\".\")[0]\n",
    "                all_results.append(data)\n",
    "        # save all results to one file\n",
    "        with open(f\"output_{self.run_name}/all_results.json\", 'w') as f:\n",
    "            json.dump(all_results, f)\n",
    "        \n",
    "\n",
    "    def calculate_statistics(self):\n",
    "        with open(f\"output_{self.run_name}/all_results.json\", 'r') as f:\n",
    "            all_results = json.load(f)\n",
    "\n",
    "        result_df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # extract guesses per team\n",
    "        def extract_guesses_list(row, team):\n",
    "            main_list =[]\n",
    "            for round in row['history']:\n",
    "                if round['team'].lower() == team:\n",
    "                    clue = round['spymaster_clue']\n",
    "                    guesses = []\n",
    "                    for action in round['actions']:\n",
    "                        if action['tool_call'] == 'codenames_guess_tool':\n",
    "                            guess = action['tool_args']['query']\n",
    "                            outcome = action['outcome']\n",
    "                            guesses.append((guess, outcome))\n",
    "                    main_list.append((clue, guesses))\n",
    "            return main_list\n",
    "                    \n",
    "\n",
    "        # get guesses per category per team\n",
    "        def extract_guesses_count(row, team, category):\n",
    "            counter = 0\n",
    "            for round in row['history']:\n",
    "                if round['team'].lower() == team:\n",
    "                    for action in round['actions']:\n",
    "                        if action['tool_call'] == 'codenames_guess_tool':\n",
    "                            if action['outcome'] == category:\n",
    "                                counter += 1\n",
    "            return counter\n",
    "\n",
    "        # apply functions to get statistics\n",
    "        result_df['guesses_red_list'] = result_df.apply(lambda row: extract_guesses_list(row, 'red'), axis=1)\n",
    "        result_df['guesses_blue_list'] = result_df.apply(lambda row: extract_guesses_list(row, 'blue'), axis=1)\n",
    "\n",
    "        result_df['guesses_red_correct'] = result_df.apply(lambda row: extract_guesses_count(row, 'red', 'correct'), axis=1)\n",
    "        result_df['guesses_red_incorrect_black'] = result_df.apply(lambda row: extract_guesses_count(row, 'red', 'incorrect - black'), axis=1)\n",
    "        result_df['guesses_red_incorrect_neutral'] = result_df.apply(lambda row: extract_guesses_count(row, 'red', 'incorrect - neutral'), axis=1)\n",
    "        result_df['guesses_red_incorrect_opponent'] = result_df.apply(lambda row: extract_guesses_count(row, 'red', 'incorrect - opponent'), axis=1)\n",
    "        result_df['guesses_red_incorrect_invalid'] = result_df.apply(lambda row: extract_guesses_count(row, 'red', 'incorrect - invalid guess'), axis=1)\n",
    "\n",
    "        result_df['guesses_blue_correct'] = result_df.apply(lambda row: extract_guesses_count(row, 'blue', 'correct'), axis=1)\n",
    "        result_df['guesses_blue_incorrect_black'] = result_df.apply(lambda row: extract_guesses_count(row, 'blue', 'incorrect - black'), axis=1)\n",
    "        result_df['guesses_blue_incorrect_neutral'] = result_df.apply(lambda row: extract_guesses_count(row, 'blue', 'incorrect - neutral'), axis=1)\n",
    "        result_df['guesses_blue_incorrect_opponent'] = result_df.apply(lambda row: extract_guesses_count(row, 'blue', 'incorrect - opponent'), axis=1)\n",
    "        result_df['guesses_blue_incorrect_invalid'] = result_df.apply(lambda row: extract_guesses_count(row, 'blue', 'incorrect - invalid guess'), axis=1)\n",
    "        \n",
    "        # save result_df\n",
    "        result_df.to_json(f\"output_{self.run_name}/all_results_stats.json\")\n",
    "\n",
    "        # display statistics\n",
    "        display(result_df)\n",
    "\n",
    "\n",
    "    def save_graph(self):\n",
    "        # most of this function is just dummy code which is needed to get the graph\n",
    "        game = Game(\"baseline\")\n",
    "        abot = Agent(self.models, game, \"xxx\", tools=[GuessTool(game),DiscussTool(),EndTurnTool()], max_rounds=self.max_rounds)\n",
    "        png_graph = abot.graph.get_graph().draw_mermaid_png()\n",
    "        with open(f\"output_{self.run_name}/graph.png\", \"wb\") as f:\n",
    "            f.write(png_graph)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Only this cell has to be customized for the different prompts and number of teammates.\n",
    "\"\"\"\n",
    "\n",
    "# for each type of player a list exists, which contains the prompts for the different models\n",
    "models = {\n",
    "    \"spymaster_BLUE\": [\n",
    "        {\"model\": None, \"system\": load_prompt_from_file('spymaster_system_prompt.txt')}\n",
    "        ],\n",
    "    \"spymaster_RED\": [\n",
    "        {\"model\": None, \"system\": load_prompt_from_file('spymaster_system_prompt.txt')}\n",
    "        ],\n",
    "    \"teammembers_BLUE\": [\n",
    "        {\"model\": None, \"system\": load_prompt_from_file('teammember_system_prompt.txt')},\n",
    "        {\"model\": None, \"system\": load_prompt_from_file('teammember_system_prompt.txt')}\n",
    "        ],\n",
    "    \"teammembers_RED\": [\n",
    "        {\"model\": None, \"system\": load_prompt_from_file('Prompts/teammember/teammember_system_prompt_risk_avoiding.txt')},\n",
    "        {\"model\": None, \"system\": load_prompt_from_file('Prompts/teammember/teammember_system_prompt_risk_avoiding.txt')}\n",
    "        ]\n",
    "}\n",
    "\n",
    "# create the game series\n",
    "game_series = Game_Series(models, \"riskavoiding\", max_rounds=15, recovery_run=False, board_random_states=range(10), wordlist='wordlist-eng.txt', run_baseline_board=True, save_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### BOARD ID: baseline ###############\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "1_spymaster_RED hint: Metal 2\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 1_teammember_RED_2\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_2qw4', 'function': {'arguments': '{\"query\": \"I think the hint Metal could relate to words like IRON or other metal objects on the board. What do you think, teammember_RED_1?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 766, 'total_tokens': 813, 'completion_time': 0.188, 'prompt_time': 0.23714391, 'queue_time': 0.0036899199999999854, 'total_time': 0.42514391}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-81000416-84d1-4880-9844-52c771ace273-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think the hint Metal could relate to words like IRON or other metal objects on the board. What do you think, teammember_RED_1?'}, 'id': 'call_2qw4', 'type': 'tool_call'}] usage_metadata={'input_tokens': 766, 'output_tokens': 47, 'total_tokens': 813}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "API Key 0 failed with error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01jahy7697e0hvmxq878h49sza` on : Limit 200000, Used 199765, Requested 390. Please try again in 1m6.717999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}. Switching to next API Key in 10 seconds.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "1_spymaster_RED hint: Metal 2\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 1_teammember_RED_2\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_njz0', 'function': {'arguments': '{\"query\": \"I think the hint Metal could relate to words like IRON or other metal objects on the board. What do you think, teammember_RED_1?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 766, 'total_tokens': 813, 'completion_time': 0.188, 'prompt_time': 0.228492887, 'queue_time': 0.8044010930000001, 'total_time': 0.416492887}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-46b2075d-7e14-4e34-a52b-4ca6f5ef5e91-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think the hint Metal could relate to words like IRON or other metal objects on the board. What do you think, teammember_RED_1?'}, 'id': 'call_njz0', 'type': 'tool_call'}] usage_metadata={'input_tokens': 766, 'output_tokens': 47, 'total_tokens': 813}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 1_teammember_RED_1\n",
      "Current Discussion: \n",
      " teammember_RED_2 said: 'I think the hint Metal could relate to words like IRON or other metal objects on the board. What do you think, teammember_RED_1?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_gvg4', 'function': {'arguments': '{\"query\": \"I agree, IRON is a strong possibility. I also think we should consider other metal objects like GROUND is unlikely but SKYSCRAPER could be a stretch. What do you think about SKYSCRAPER?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 799, 'total_tokens': 859, 'completion_time': 0.24, 'prompt_time': 0.138340083, 'queue_time': 0.0035972870000000046, 'total_time': 0.378340083}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-843bf87d-54ce-4162-8ca4-b1fe0ebc7bf7-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree, IRON is a strong possibility. I also think we should consider other metal objects like GROUND is unlikely but SKYSCRAPER could be a stretch. What do you think about SKYSCRAPER?'}, 'id': 'call_gvg4', 'type': 'tool_call'}] usage_metadata={'input_tokens': 799, 'output_tokens': 60, 'total_tokens': 859}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "API Key 1 failed with error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01jd2eztsffjybt38xfgs7wgb0` on : Limit 200000, Used 200465, Requested 439. Please try again in 6m30.735s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}. Switching to next API Key in 10 seconds.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "1_spymaster_RED hint: Metal 2\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 1_teammember_RED_2\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_455f', 'function': {'arguments': '{\"query\": \"I think the hint Metal could relate to words like IRON or other metal objects on the board. What do you think, teammember_RED_1?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 766, 'total_tokens': 813, 'completion_time': 0.188, 'prompt_time': 0.140272201, 'queue_time': 0.0036567889999999936, 'total_time': 0.328272201}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-32377673-b24c-4d85-9f07-ef03499a5165-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think the hint Metal could relate to words like IRON or other metal objects on the board. What do you think, teammember_RED_1?'}, 'id': 'call_455f', 'type': 'tool_call'}] usage_metadata={'input_tokens': 766, 'output_tokens': 47, 'total_tokens': 813}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 1_teammember_RED_1\n",
      "Current Discussion: \n",
      " teammember_RED_2 said: 'I think the hint Metal could relate to words like IRON or other metal objects on the board. What do you think, teammember_RED_1?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_9h7x', 'function': {'arguments': '{\"query\": \"I agree, IRON is a strong possibility. I also think we should consider other metal objects like GROUND is unlikely but SKYSCRAPER could be a stretch. What do you think about SKYSCRAPER?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 799, 'total_tokens': 859, 'completion_time': 0.24, 'prompt_time': 0.146828406, 'queue_time': 0.003689154, 'total_time': 0.386828406}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-69a268ac-e4bc-4b6c-bf5a-eaf5a1d4bc9d-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree, IRON is a strong possibility. I also think we should consider other metal objects like GROUND is unlikely but SKYSCRAPER could be a stretch. What do you think about SKYSCRAPER?'}, 'id': 'call_9h7x', 'type': 'tool_call'}] usage_metadata={'input_tokens': 799, 'output_tokens': 60, 'total_tokens': 859}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 1_teammember_RED_2\n",
      "Current Discussion: \n",
      " You said: 'I think the hint Metal could relate to words like IRON or other metal objects on the board. What do you think, teammember_RED_1?'\n",
      "teammember_RED_1 said: 'I agree, IRON is a strong possibility. I also think we should consider other metal objects like GROUND is unlikely but SKYSCRAPER could be a stretch. What do you think about SKYSCRAPER?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_abbb', 'function': {'arguments': '{\"query\": \"I think SKYSCRAPER is a bit of a stretch, but I do think we should consider other metal objects like the RULER on the board. What do you think about RULER?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 848, 'total_tokens': 903, 'completion_time': 0.22, 'prompt_time': 0.155790818, 'queue_time': 0.0034561019999999887, 'total_time': 0.375790818}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-bba67c15-3513-4730-b767-67963f07ebac-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think SKYSCRAPER is a bit of a stretch, but I do think we should consider other metal objects like the RULER on the board. What do you think about RULER?'}, 'id': 'call_abbb', 'type': 'tool_call'}] usage_metadata={'input_tokens': 848, 'output_tokens': 55, 'total_tokens': 903}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 1_teammember_RED_1\n",
      "Current Discussion: \n",
      " teammember_RED_2 said: 'I think the hint Metal could relate to words like IRON or other metal objects on the board. What do you think, teammember_RED_1?'\n",
      "You said: 'I agree, IRON is a strong possibility. I also think we should consider other metal objects like GROUND is unlikely but SKYSCRAPER could be a stretch. What do you think about SKYSCRAPER?'\n",
      "teammember_RED_2 said: 'I think SKYSCRAPER is a bit of a stretch, but I do think we should consider other metal objects like the RULER on the board. What do you think about RULER?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_qamf', 'function': {'arguments': '{\"query\": \"I think RULER is a strong possibility, but I still think IRON is the most likely. What do you think we should guess?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 897, 'total_tokens': 941, 'completion_time': 0.176, 'prompt_time': 0.171784673, 'queue_time': 0.003537106000000012, 'total_time': 0.347784673}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-3d98664e-54a2-4827-bcf3-715bdea4077b-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think RULER is a strong possibility, but I still think IRON is the most likely. What do you think we should guess?'}, 'id': 'call_qamf', 'type': 'tool_call'}] usage_metadata={'input_tokens': 897, 'output_tokens': 44, 'total_tokens': 941}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 1_teammember_RED_2\n",
      "Current Discussion: \n",
      " You said: 'I think the hint Metal could relate to words like IRON or other metal objects on the board. What do you think, teammember_RED_1?'\n",
      "teammember_RED_1 said: 'I agree, IRON is a strong possibility. I also think we should consider other metal objects like GROUND is unlikely but SKYSCRAPER could be a stretch. What do you think about SKYSCRAPER?'\n",
      "You said: 'I think SKYSCRAPER is a bit of a stretch, but I do think we should consider other metal objects like the RULER on the board. What do you think about RULER?'\n",
      "teammember_RED_1 said: 'I think RULER is a strong possibility, but I still think IRON is the most likely. What do you think we should guess?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_dmr8', 'function': {'arguments': '{\"query\": \"IRON\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_g8y2', 'function': {'arguments': '{\"query\": \"I think we should guess IRON, but we should also be prepared to end our turn after this guess.\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}, {'id': 'call_ks50', 'function': {'arguments': '{\"query\": \"end turn\"}', 'name': 'codenames_end_turn_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 930, 'total_tokens': 1002, 'completion_time': 0.288, 'prompt_time': 0.161912632, 'queue_time': 0.003726457999999988, 'total_time': 0.449912632}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-525ba113-7e5d-48d2-9d02-0b6c3c8f1566-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'IRON'}, 'id': 'call_dmr8', 'type': 'tool_call'}, {'name': 'codenames_discuss_tool', 'args': {'query': 'I think we should guess IRON, but we should also be prepared to end our turn after this guess.'}, 'id': 'call_g8y2', 'type': 'tool_call'}, {'name': 'codenames_end_turn_tool', 'args': {'query': 'end turn'}, 'id': 'call_ks50', 'type': 'tool_call'}] usage_metadata={'input_tokens': 930, 'output_tokens': 72, 'total_tokens': 1002}\n",
      "Correct! {'query': 'IRON'} belongs to team red.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "1_spymaster_BLUE hint: BUILDING 3\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 1_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_b8tg', 'function': {'arguments': '{\"query\": \"What are your thoughts on the hint BUILDING? Should we start with the obvious ones like SKYSCRAPER or STADIUM?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 756, 'total_tokens': 799, 'completion_time': 0.172, 'prompt_time': 0.130555121, 'queue_time': 0.004058896000000006, 'total_time': 0.302555121}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-1e8b1e50-66ea-4001-a339-401ad90d9ea3-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'What are your thoughts on the hint BUILDING? Should we start with the obvious ones like SKYSCRAPER or STADIUM?'}, 'id': 'call_b8tg', 'type': 'tool_call'}] usage_metadata={'input_tokens': 756, 'output_tokens': 43, 'total_tokens': 799}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 1_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " teammember_BLUE_2 said: 'What are your thoughts on the hint BUILDING? Should we start with the obvious ones like SKYSCRAPER or STADIUM?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_f6we', 'function': {'arguments': '{\"query\": \"I think we should start with the obvious ones like SKYSCRAPER or STADIUM. What about BLOCK? It could also be related to a building.\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 785, 'total_tokens': 833, 'completion_time': 0.192, 'prompt_time': 0.159796209, 'queue_time': 0.0033374820000000027, 'total_time': 0.351796209}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-ce18d39e-fff6-453f-8651-fbc491777e15-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think we should start with the obvious ones like SKYSCRAPER or STADIUM. What about BLOCK? It could also be related to a building.'}, 'id': 'call_f6we', 'type': 'tool_call'}] usage_metadata={'input_tokens': 785, 'output_tokens': 48, 'total_tokens': 833}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 1_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " You said: 'What are your thoughts on the hint BUILDING? Should we start with the obvious ones like SKYSCRAPER or STADIUM?'\n",
      "teammember_BLUE_1 said: 'I think we should start with the obvious ones like SKYSCRAPER or STADIUM. What about BLOCK? It could also be related to a building.'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_b973', 'function': {'arguments': '{\"query\": \"SKYSCRAPER\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_nazx', 'function': {'arguments': '{\"query\": \"STADIUM\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_pp8n', 'function': {'arguments': '{\"query\": \"BLOCK\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_bwt2', 'function': {'arguments': '{\"query\": \"What do you think about GROUND? Could it be related to the foundation of a building?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 822, 'total_tokens': 910, 'completion_time': 0.352, 'prompt_time': 0.176557138, 'queue_time': 0.003543961999999984, 'total_time': 0.528557138}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-b86de656-6464-423f-b1dd-b70538060274-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'SKYSCRAPER'}, 'id': 'call_b973', 'type': 'tool_call'}, {'name': 'codenames_guess_tool', 'args': {'query': 'STADIUM'}, 'id': 'call_nazx', 'type': 'tool_call'}, {'name': 'codenames_guess_tool', 'args': {'query': 'BLOCK'}, 'id': 'call_pp8n', 'type': 'tool_call'}, {'name': 'codenames_discuss_tool', 'args': {'query': 'What do you think about GROUND? Could it be related to the foundation of a building?'}, 'id': 'call_bwt2', 'type': 'tool_call'}] usage_metadata={'input_tokens': 822, 'output_tokens': 88, 'total_tokens': 910}\n",
      "Correct! {'query': 'SKYSCRAPER'} belongs to team blue.\n",
      "Correct! {'query': 'STADIUM'} belongs to team blue.\n",
      "Correct! {'query': 'BLOCK'} belongs to team blue.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "2_spymaster_RED hint: WHITE 2\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 2_teammember_RED_1\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_a5f6', 'function': {'arguments': '{\"query\": \"What are your thoughts on the hint WHITE 2? Any ideas on which words might be related?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 752, 'total_tokens': 788, 'completion_time': 0.144, 'prompt_time': 0.216011026, 'queue_time': 0.004904946999999993, 'total_time': 0.360011026}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d988abd3-da80-44b9-ab53-4236b39063a7-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'What are your thoughts on the hint WHITE 2? Any ideas on which words might be related?'}, 'id': 'call_a5f6', 'type': 'tool_call'}] usage_metadata={'input_tokens': 752, 'output_tokens': 36, 'total_tokens': 788}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 2_teammember_RED_2\n",
      "Current Discussion: \n",
      " teammember_RED_1 said: 'What are your thoughts on the hint WHITE 2? Any ideas on which words might be related?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_vfwq', 'function': {'arguments': '{\"query\": \"I think IVORY and ICE CREAM could be related to WHITE. What do you think?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 774, 'total_tokens': 809, 'completion_time': 0.14, 'prompt_time': 0.132212607, 'queue_time': 0.0036715129999999874, 'total_time': 0.272212607}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d257c492-9c27-4f1a-be20-02d60913d3e5-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think IVORY and ICE CREAM could be related to WHITE. What do you think?'}, 'id': 'call_vfwq', 'type': 'tool_call'}] usage_metadata={'input_tokens': 774, 'output_tokens': 35, 'total_tokens': 809}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 2_teammember_RED_1\n",
      "Current Discussion: \n",
      " You said: 'What are your thoughts on the hint WHITE 2? Any ideas on which words might be related?'\n",
      "teammember_RED_2 said: 'I think IVORY and ICE CREAM could be related to WHITE. What do you think?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_3f7y', 'function': {'arguments': '{\"query\": \"I agree with you on IVORY, but I am not sure about ICE CREAM. What about OIL, could it be related to WHITE as in white oil?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 798, 'total_tokens': 848, 'completion_time': 0.2, 'prompt_time': 0.155816404, 'queue_time': 0.003698429000000003, 'total_time': 0.355816404}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-b59780dc-5ad9-465d-a676-350474bfcae4-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree with you on IVORY, but I am not sure about ICE CREAM. What about OIL, could it be related to WHITE as in white oil?'}, 'id': 'call_3f7y', 'type': 'tool_call'}] usage_metadata={'input_tokens': 798, 'output_tokens': 50, 'total_tokens': 848}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 2_teammember_RED_2\n",
      "Current Discussion: \n",
      " teammember_RED_1 said: 'What are your thoughts on the hint WHITE 2? Any ideas on which words might be related?'\n",
      "You said: 'I think IVORY and ICE CREAM could be related to WHITE. What do you think?'\n",
      "teammember_RED_1 said: 'I agree with you on IVORY, but I am not sure about ICE CREAM. What about OIL, could it be related to WHITE as in white oil?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_n803', 'function': {'arguments': '{\"query\": \"I agree with you on IVORY, and I also think IVORY is a stronger connection to WHITE than OIL. I am going to guess IVORY.\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}, {'id': 'call_phwd', 'function': {'arguments': '{\"query\": \"IVORY\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_f9aa', 'function': {'arguments': '{\"query\": \"\"}', 'name': 'codenames_end_turn_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 842, 'total_tokens': 922, 'completion_time': 0.32, 'prompt_time': 0.144503101, 'queue_time': 0.003448054000000006, 'total_time': 0.464503101}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-473cd9c6-3bed-43fe-b56c-899f786d3883-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree with you on IVORY, and I also think IVORY is a stronger connection to WHITE than OIL. I am going to guess IVORY.'}, 'id': 'call_n803', 'type': 'tool_call'}, {'name': 'codenames_guess_tool', 'args': {'query': 'IVORY'}, 'id': 'call_phwd', 'type': 'tool_call'}, {'name': 'codenames_end_turn_tool', 'args': {'query': ''}, 'id': 'call_f9aa', 'type': 'tool_call'}] usage_metadata={'input_tokens': 842, 'output_tokens': 80, 'total_tokens': 922}\n",
      "Correct! {'query': 'IVORY'} belongs to team red.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "2_spymaster_BLUE hint: FLIGHT 2\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 2_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_dmef', 'function': {'arguments': '{\"query\": \"What are your thoughts on the hint FLIGHT? Should we focus on words related to flying or the airline industry?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 736, 'total_tokens': 775, 'completion_time': 0.156, 'prompt_time': 0.135287307, 'queue_time': 0.0036992230000000015, 'total_time': 0.291287307}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-2033ec5c-8ebf-4c39-ba61-5f237f7f0217-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'What are your thoughts on the hint FLIGHT? Should we focus on words related to flying or the airline industry?'}, 'id': 'call_dmef', 'type': 'tool_call'}] usage_metadata={'input_tokens': 736, 'output_tokens': 39, 'total_tokens': 775}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 2_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " teammember_BLUE_1 said: 'What are your thoughts on the hint FLIGHT? Should we focus on words related to flying or the airline industry?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_2f9a', 'function': {'arguments': '{\"query\": \"I think we should focus on words related to flying. PILOT is a strong candidate, and possibly SHARK could be related to a flying shark, but that seems a bit far-fetched. What do you think about PILOT?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 761, 'total_tokens': 824, 'completion_time': 0.252, 'prompt_time': 0.130691209, 'queue_time': 0.0037784309999999988, 'total_time': 0.382691209}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-90a5f70f-5b10-4f1d-8e78-fb5d1f986928-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think we should focus on words related to flying. PILOT is a strong candidate, and possibly SHARK could be related to a flying shark, but that seems a bit far-fetched. What do you think about PILOT?'}, 'id': 'call_2f9a', 'type': 'tool_call'}] usage_metadata={'input_tokens': 761, 'output_tokens': 63, 'total_tokens': 824}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 2_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " You said: 'What are your thoughts on the hint FLIGHT? Should we focus on words related to flying or the airline industry?'\n",
      "teammember_BLUE_2 said: 'I think we should focus on words related to flying. PILOT is a strong candidate, and possibly SHARK could be related to a flying shark, but that seems a bit far-fetched. What do you think about PILOT?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_b227', 'function': {'arguments': '{\"query\": \"I agree with you on PILOT, it seems like a strong candidate. I also think FLY could be related to the hint. What do you think about FLY?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 813, 'total_tokens': 864, 'completion_time': 0.204, 'prompt_time': 0.150459551, 'queue_time': 0.0035296989999999973, 'total_time': 0.354459551}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-c2fa2a4e-b959-4ae7-a26e-ad4a27d030fe-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree with you on PILOT, it seems like a strong candidate. I also think FLY could be related to the hint. What do you think about FLY?'}, 'id': 'call_b227', 'type': 'tool_call'}] usage_metadata={'input_tokens': 813, 'output_tokens': 51, 'total_tokens': 864}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 2_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " teammember_BLUE_1 said: 'What are your thoughts on the hint FLIGHT? Should we focus on words related to flying or the airline industry?'\n",
      "You said: 'I think we should focus on words related to flying. PILOT is a strong candidate, and possibly SHARK could be related to a flying shark, but that seems a bit far-fetched. What do you think about PILOT?'\n",
      "teammember_BLUE_1 said: 'I agree with you on PILOT, it seems like a strong candidate. I also think FLY could be related to the hint. What do you think about FLY?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_rap7', 'function': {'arguments': '{\"query\": \"PILOT\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_npf4', 'function': {'arguments': '{\"query\": \"FLY\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_exvy', 'function': {'arguments': '{\"query\": \"I agree with you on FLY, it seems like a strong candidate. I also think we should consider SHARK, although it is a bit far-fetched. What do you think about SHARK?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 858, 'total_tokens': 949, 'completion_time': 0.364, 'prompt_time': 0.202288657, 'queue_time': 0.03855846299999999, 'total_time': 0.566288657}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-b8680984-beed-469c-a7c6-4be86f719424-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'PILOT'}, 'id': 'call_rap7', 'type': 'tool_call'}, {'name': 'codenames_guess_tool', 'args': {'query': 'FLY'}, 'id': 'call_npf4', 'type': 'tool_call'}, {'name': 'codenames_discuss_tool', 'args': {'query': 'I agree with you on FLY, it seems like a strong candidate. I also think we should consider SHARK, although it is a bit far-fetched. What do you think about SHARK?'}, 'id': 'call_exvy', 'type': 'tool_call'}] usage_metadata={'input_tokens': 858, 'output_tokens': 91, 'total_tokens': 949}\n",
      "Correct! {'query': 'PILOT'} belongs to team blue.\n",
      "Incorrect! {'query': 'FLY'} is a red word.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "3_spymaster_RED hint: Cold 2\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 3_teammember_RED_1\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_axxa', 'function': {'arguments': '{\"query\": \"I think the hint Cold could relate to ICE CREAM or something else cold. What do you think, teammember_RED_2?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 743, 'total_tokens': 786, 'completion_time': 0.172, 'prompt_time': 0.129449899, 'queue_time': 0.004114298999999988, 'total_time': 0.301449899}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-e6245c08-5e84-4113-a334-eb67726d70cc-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think the hint Cold could relate to ICE CREAM or something else cold. What do you think, teammember_RED_2?'}, 'id': 'call_axxa', 'type': 'tool_call'}] usage_metadata={'input_tokens': 743, 'output_tokens': 43, 'total_tokens': 786}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 3_teammember_RED_2\n",
      "Current Discussion: \n",
      " teammember_RED_1 said: 'I think the hint Cold could relate to ICE CREAM or something else cold. What do you think, teammember_RED_2?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_ec8z', 'function': {'arguments': '{\"query\": \"I agree, ICE CREAM is a good guess, but we should also consider other cold-related words like ICE, but it is not on the board. What about other cold-related words?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 772, 'total_tokens': 826, 'completion_time': 0.216, 'prompt_time': 0.137305346, 'queue_time': 0.0037794429999999934, 'total_time': 0.353305346}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-dab6f91d-bc50-4eb0-8b72-036fc9c1503a-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree, ICE CREAM is a good guess, but we should also consider other cold-related words like ICE, but it is not on the board. What about other cold-related words?'}, 'id': 'call_ec8z', 'type': 'tool_call'}] usage_metadata={'input_tokens': 772, 'output_tokens': 54, 'total_tokens': 826}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 3_teammember_RED_1\n",
      "Current Discussion: \n",
      " You said: 'I think the hint Cold could relate to ICE CREAM or something else cold. What do you think, teammember_RED_2?'\n",
      "teammember_RED_2 said: 'I agree, ICE CREAM is a good guess, but we should also consider other cold-related words like ICE, but it is not on the board. What about other cold-related words?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_hyeg', 'function': {'arguments': '{\"query\": \"I think we should also consider the word COLD is not on the board, but what about words that are cold in nature like ICE CREAM or something that can be found in cold places. What are your thoughts?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}, {'id': 'call_yvj4', 'function': {'arguments': '{\"query\": \"ICE CREAM\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_zhsc', 'function': {'arguments': '{\"query\": \"I am ending my turn after guessing one word.\"}', 'name': 'codenames_end_turn_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 103, 'prompt_tokens': 815, 'total_tokens': 918, 'completion_time': 0.412, 'prompt_time': 0.162208793, 'queue_time': 0.003605857000000018, 'total_time': 0.574208793}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-c0b20393-d110-4766-b37d-d0939b59b3b7-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think we should also consider the word COLD is not on the board, but what about words that are cold in nature like ICE CREAM or something that can be found in cold places. What are your thoughts?'}, 'id': 'call_hyeg', 'type': 'tool_call'}, {'name': 'codenames_guess_tool', 'args': {'query': 'ICE CREAM'}, 'id': 'call_yvj4', 'type': 'tool_call'}, {'name': 'codenames_end_turn_tool', 'args': {'query': 'I am ending my turn after guessing one word.'}, 'id': 'call_zhsc', 'type': 'tool_call'}] usage_metadata={'input_tokens': 815, 'output_tokens': 103, 'total_tokens': 918}\n",
      "Correct! {'query': 'ICE CREAM'} belongs to team red.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "3_spymaster_BLUE hint: CLOTH 2\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 3_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_vsey', 'function': {'arguments': '{\"query\": \"What do you think about the hint CLOTH? I think it might relate to something we wear or something that is used to clean.\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 727, 'total_tokens': 771, 'completion_time': 0.176, 'prompt_time': 0.124921643, 'queue_time': 0.0036730359999999906, 'total_time': 0.300921643}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-47870e0e-29ad-4ea7-88e0-5696e68d489e-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'What do you think about the hint CLOTH? I think it might relate to something we wear or something that is used to clean.'}, 'id': 'call_vsey', 'type': 'tool_call'}] usage_metadata={'input_tokens': 727, 'output_tokens': 44, 'total_tokens': 771}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 3_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " teammember_BLUE_1 said: 'What do you think about the hint CLOTH? I think it might relate to something we wear or something that is used to clean.'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_f858', 'function': {'arguments': '{\"query\": \"I agree, it could be something we wear. I think CLOAK is a strong possibility since it is directly related to cloth. What do you think about CLOAK?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 757, 'total_tokens': 809, 'completion_time': 0.208, 'prompt_time': 0.141059573, 'queue_time': 0.10793797700000002, 'total_time': 0.349059573}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-43b9ede7-bee8-44d1-9b83-5a3605af4b92-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree, it could be something we wear. I think CLOAK is a strong possibility since it is directly related to cloth. What do you think about CLOAK?'}, 'id': 'call_f858', 'type': 'tool_call'}] usage_metadata={'input_tokens': 757, 'output_tokens': 52, 'total_tokens': 809}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 3_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " You said: 'What do you think about the hint CLOTH? I think it might relate to something we wear or something that is used to clean.'\n",
      "teammember_BLUE_2 said: 'I agree, it could be something we wear. I think CLOAK is a strong possibility since it is directly related to cloth. What do you think about CLOAK?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_z6x5', 'function': {'arguments': '{\"query\": \"I agree with you about CLOAK, it is a strong possibility. I also think we should consider other options like something used to clean, but CLOAK seems like the safest bet. What do you think about guessing CLOAK?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 797, 'total_tokens': 862, 'completion_time': 0.26, 'prompt_time': 0.145598145, 'queue_time': 0.0035223539999999776, 'total_time': 0.405598145}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-2a093ff7-6ac5-4a0f-a819-7a3663babde1-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree with you about CLOAK, it is a strong possibility. I also think we should consider other options like something used to clean, but CLOAK seems like the safest bet. What do you think about guessing CLOAK?'}, 'id': 'call_z6x5', 'type': 'tool_call'}] usage_metadata={'input_tokens': 797, 'output_tokens': 65, 'total_tokens': 862}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 3_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " teammember_BLUE_1 said: 'What do you think about the hint CLOTH? I think it might relate to something we wear or something that is used to clean.'\n",
      "You said: 'I agree, it could be something we wear. I think CLOAK is a strong possibility since it is directly related to cloth. What do you think about CLOAK?'\n",
      "teammember_BLUE_1 said: 'I agree with you about CLOAK, it is a strong possibility. I also think we should consider other options like something used to clean, but CLOAK seems like the safest bet. What do you think about guessing CLOAK?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_6bhh', 'function': {'arguments': '{\"query\": \"CLOAK\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 856, 'total_tokens': 875, 'completion_time': 0.076, 'prompt_time': 0.157957045, 'queue_time': 0.190435803, 'total_time': 0.233957045}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-63552a14-969c-4f32-a52f-abe6e13ed117-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'CLOAK'}, 'id': 'call_6bhh', 'type': 'tool_call'}] usage_metadata={'input_tokens': 856, 'output_tokens': 19, 'total_tokens': 875}\n",
      "Correct! {'query': 'CLOAK'} belongs to team blue.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 3_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " You said: 'What do you think about the hint CLOTH? I think it might relate to something we wear or something that is used to clean.'\n",
      "teammember_BLUE_2 said: 'I agree, it could be something we wear. I think CLOAK is a strong possibility since it is directly related to cloth. What do you think about CLOAK?'\n",
      "You said: 'I agree with you about CLOAK, it is a strong possibility. I also think we should consider other options like something used to clean, but CLOAK seems like the safest bet. What do you think about guessing CLOAK?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_f27f', 'function': {'arguments': '{\"query\": \"Since CLOAK was already guessed correctly, I think we should focus on the second word related to CLOTH. I was thinking about something used to clean, like a cloth used to wipe or clean surfaces. Do you think there is a word on the board that could fit this description?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 854, 'total_tokens': 929, 'completion_time': 0.3, 'prompt_time': 0.158088113, 'queue_time': 0.003705995999999989, 'total_time': 0.458088113}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-e38a1ed0-cfbf-41a9-94c1-6ac87c17c11a-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'Since CLOAK was already guessed correctly, I think we should focus on the second word related to CLOTH. I was thinking about something used to clean, like a cloth used to wipe or clean surfaces. Do you think there is a word on the board that could fit this description?'}, 'id': 'call_f27f', 'type': 'tool_call'}] usage_metadata={'input_tokens': 854, 'output_tokens': 75, 'total_tokens': 929}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 3_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " teammember_BLUE_1 said: 'What do you think about the hint CLOTH? I think it might relate to something we wear or something that is used to clean.'\n",
      "You said: 'I agree, it could be something we wear. I think CLOAK is a strong possibility since it is directly related to cloth. What do you think about CLOAK?'\n",
      "teammember_BLUE_1 said: 'I agree with you about CLOAK, it is a strong possibility. I also think we should consider other options like something used to clean, but CLOAK seems like the safest bet. What do you think about guessing CLOAK?'\n",
      "teammember_BLUE_1 said: 'Since CLOAK was already guessed correctly, I think we should focus on the second word related to CLOTH. I was thinking about something used to clean, like a cloth used to wipe or clean surfaces. Do you think there is a word on the board that could fit this description?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_xda1', 'function': {'arguments': '{\"query\": \"I think you are on the right track with the cleaning idea. I was thinking about KETCHUP, it is not directly related to cleaning, but it is a type of cloth or material used to clean or wipe surfaces in a sense. What do you think about KETCHUP?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 928, 'total_tokens': 1001, 'completion_time': 0.292, 'prompt_time': 0.162130629, 'queue_time': 0.003962790999999993, 'total_time': 0.454130629}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-54f771e8-d74c-4c18-b6bc-ba719209f79c-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think you are on the right track with the cleaning idea. I was thinking about KETCHUP, it is not directly related to cleaning, but it is a type of cloth or material used to clean or wipe surfaces in a sense. What do you think about KETCHUP?'}, 'id': 'call_xda1', 'type': 'tool_call'}] usage_metadata={'input_tokens': 928, 'output_tokens': 73, 'total_tokens': 1001}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 3_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " You said: 'What do you think about the hint CLOTH? I think it might relate to something we wear or something that is used to clean.'\n",
      "teammember_BLUE_2 said: 'I agree, it could be something we wear. I think CLOAK is a strong possibility since it is directly related to cloth. What do you think about CLOAK?'\n",
      "You said: 'I agree with you about CLOAK, it is a strong possibility. I also think we should consider other options like something used to clean, but CLOAK seems like the safest bet. What do you think about guessing CLOAK?'\n",
      "You said: 'Since CLOAK was already guessed correctly, I think we should focus on the second word related to CLOTH. I was thinking about something used to clean, like a cloth used to wipe or clean surfaces. Do you think there is a word on the board that could fit this description?'\n",
      "teammember_BLUE_2 said: 'I think you are on the right track with the cleaning idea. I was thinking about KETCHUP, it is not directly related to cleaning, but it is a type of cloth or material used to clean or wipe surfaces in a sense. What do you think about KETCHUP?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_z07x', 'function': {'arguments': '{\"query\": \"KETCHUP\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 985, 'total_tokens': 1004, 'completion_time': 0.076, 'prompt_time': 0.175274062, 'queue_time': 0.0036951379999999867, 'total_time': 0.251274062}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-aaadecc8-0928-4cc3-9b4b-8c6c68bc7753-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'KETCHUP'}, 'id': 'call_z07x', 'type': 'tool_call'}] usage_metadata={'input_tokens': 985, 'output_tokens': 19, 'total_tokens': 1004}\n",
      "Correct! {'query': 'KETCHUP'} belongs to team blue.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "4_spymaster_RED hint: INTELLIGENCE 2\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 4_teammember_RED_2\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_z9jd', 'function': {'arguments': '{\"query\": \"I think the hint INTELLIGENCE could relate to GENIUS or LAWYER, both are on the board. What do you think, teammember_RED_1?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 734, 'total_tokens': 786, 'completion_time': 0.208, 'prompt_time': 0.126973261, 'queue_time': 0.003614578000000007, 'total_time': 0.334973261}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-303a0343-2075-4255-9230-b67a103eefaf-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think the hint INTELLIGENCE could relate to GENIUS or LAWYER, both are on the board. What do you think, teammember_RED_1?'}, 'id': 'call_z9jd', 'type': 'tool_call'}] usage_metadata={'input_tokens': 734, 'output_tokens': 52, 'total_tokens': 786}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 4_teammember_RED_1\n",
      "Current Discussion: \n",
      " teammember_RED_2 said: 'I think the hint INTELLIGENCE could relate to GENIUS or LAWYER, both are on the board. What do you think, teammember_RED_1?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_x220', 'function': {'arguments': '{\"query\": \"I agree, both GENIUS and LAWYER are strong possibilities. I think GENIUS is a more direct relation to INTELLIGENCE, but we should also consider the other words on the board that might fit the hint. What do you think about KID, could it be related to child intelligence or prodigy?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 772, 'total_tokens': 855, 'completion_time': 0.332, 'prompt_time': 0.135228583, 'queue_time': 0.003916026999999989, 'total_time': 0.467228583}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-c48345cb-b3aa-48af-a2ab-3698a1e97ad1-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree, both GENIUS and LAWYER are strong possibilities. I think GENIUS is a more direct relation to INTELLIGENCE, but we should also consider the other words on the board that might fit the hint. What do you think about KID, could it be related to child intelligence or prodigy?'}, 'id': 'call_x220', 'type': 'tool_call'}] usage_metadata={'input_tokens': 772, 'output_tokens': 83, 'total_tokens': 855}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 4_teammember_RED_2\n",
      "Current Discussion: \n",
      " You said: 'I think the hint INTELLIGENCE could relate to GENIUS or LAWYER, both are on the board. What do you think, teammember_RED_1?'\n",
      "teammember_RED_1 said: 'I agree, both GENIUS and LAWYER are strong possibilities. I think GENIUS is a more direct relation to INTELLIGENCE, but we should also consider the other words on the board that might fit the hint. What do you think about KID, could it be related to child intelligence or prodigy?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_ymdt', 'function': {'arguments': '{\"query\": \"I see what you mean about KID, but I think it is a bit of a stretch. I still think GENIUS is the most direct relation to INTELLIGENCE. What do you think about guessing GENIUS and then ending our turn?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 844, 'total_tokens': 912, 'completion_time': 0.272, 'prompt_time': 0.164451138, 'queue_time': 0.052660771999999995, 'total_time': 0.436451138}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-018e6c47-6e0a-47d6-979f-50cd59408d40-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I see what you mean about KID, but I think it is a bit of a stretch. I still think GENIUS is the most direct relation to INTELLIGENCE. What do you think about guessing GENIUS and then ending our turn?'}, 'id': 'call_ymdt', 'type': 'tool_call'}] usage_metadata={'input_tokens': 844, 'output_tokens': 68, 'total_tokens': 912}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 4_teammember_RED_1\n",
      "Current Discussion: \n",
      " teammember_RED_2 said: 'I think the hint INTELLIGENCE could relate to GENIUS or LAWYER, both are on the board. What do you think, teammember_RED_1?'\n",
      "You said: 'I agree, both GENIUS and LAWYER are strong possibilities. I think GENIUS is a more direct relation to INTELLIGENCE, but we should also consider the other words on the board that might fit the hint. What do you think about KID, could it be related to child intelligence or prodigy?'\n",
      "teammember_RED_2 said: 'I see what you mean about KID, but I think it is a bit of a stretch. I still think GENIUS is the most direct relation to INTELLIGENCE. What do you think about guessing GENIUS and then ending our turn?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_a9kr', 'function': {'arguments': '{\"query\": \"GENIUS\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_mw1z', 'function': {'arguments': '{\"query\": \"Ending turn after guessing GENIUS\"}', 'name': 'codenames_end_turn_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 906, 'total_tokens': 948, 'completion_time': 0.168, 'prompt_time': 0.220465406, 'queue_time': 0.195315932, 'total_time': 0.388465406}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-a55d3878-cf0c-4fb2-9a78-fd504da3ae88-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'GENIUS'}, 'id': 'call_a9kr', 'type': 'tool_call'}, {'name': 'codenames_end_turn_tool', 'args': {'query': 'Ending turn after guessing GENIUS'}, 'id': 'call_mw1z', 'type': 'tool_call'}] usage_metadata={'input_tokens': 906, 'output_tokens': 42, 'total_tokens': 948}\n",
      "Correct! {'query': 'GENIUS'} belongs to team red.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "4_spymaster_BLUE hint: Chemical 2\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 4_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_7cj7', 'function': {'arguments': '{\"query\": \"I think the hint Chemical 2 could relate to OIL and COMPOUND, both are on the board and have a direct relation to chemicals. What do you think teammember_BLUE_1?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 713, 'total_tokens': 769, 'completion_time': 0.224, 'prompt_time': 0.124157363, 'queue_time': 0.003988696999999999, 'total_time': 0.348157363}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-18a4343d-c0e1-4a99-8f75-d93c96792bd3-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think the hint Chemical 2 could relate to OIL and COMPOUND, both are on the board and have a direct relation to chemicals. What do you think teammember_BLUE_1?'}, 'id': 'call_7cj7', 'type': 'tool_call'}] usage_metadata={'input_tokens': 713, 'output_tokens': 56, 'total_tokens': 769}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 4_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " teammember_BLUE_2 said: 'I think the hint Chemical 2 could relate to OIL and COMPOUND, both are on the board and have a direct relation to chemicals. What do you think teammember_BLUE_1?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_g5v6', 'function': {'arguments': '{\"query\": \"I agree with you, OIL and COMPOUND are strong possibilities. I also think we should consider BOMB, as it can be a chemical explosive. What are your thoughts on BOMB?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 755, 'total_tokens': 811, 'completion_time': 0.224, 'prompt_time': 0.134737114, 'queue_time': 0.0035999859999999995, 'total_time': 0.358737114}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-8611e4c2-dd18-4fce-8ef7-b7fb44fe77af-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree with you, OIL and COMPOUND are strong possibilities. I also think we should consider BOMB, as it can be a chemical explosive. What are your thoughts on BOMB?'}, 'id': 'call_g5v6', 'type': 'tool_call'}] usage_metadata={'input_tokens': 755, 'output_tokens': 56, 'total_tokens': 811}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 4_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " You said: 'I think the hint Chemical 2 could relate to OIL and COMPOUND, both are on the board and have a direct relation to chemicals. What do you think teammember_BLUE_1?'\n",
      "teammember_BLUE_1 said: 'I agree with you, OIL and COMPOUND are strong possibilities. I also think we should consider BOMB, as it can be a chemical explosive. What are your thoughts on BOMB?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_zp9p', 'function': {'arguments': '{\"query\": \"I agree with you on OIL and COMPOUND, but I am not sure about BOMB. I think it is more related to an explosive device rather than a chemical itself. What do you think about COMPOUND being a stronger possibility than BOMB?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 800, 'total_tokens': 869, 'completion_time': 0.276, 'prompt_time': 0.14377514, 'queue_time': 0.003744311, 'total_time': 0.41977514}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-95400dcf-8d97-4e6e-8329-f130d0851f04-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree with you on OIL and COMPOUND, but I am not sure about BOMB. I think it is more related to an explosive device rather than a chemical itself. What do you think about COMPOUND being a stronger possibility than BOMB?'}, 'id': 'call_zp9p', 'type': 'tool_call'}] usage_metadata={'input_tokens': 800, 'output_tokens': 69, 'total_tokens': 869}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 4_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " teammember_BLUE_2 said: 'I think the hint Chemical 2 could relate to OIL and COMPOUND, both are on the board and have a direct relation to chemicals. What do you think teammember_BLUE_1?'\n",
      "You said: 'I agree with you, OIL and COMPOUND are strong possibilities. I also think we should consider BOMB, as it can be a chemical explosive. What are your thoughts on BOMB?'\n",
      "teammember_BLUE_2 said: 'I agree with you on OIL and COMPOUND, but I am not sure about BOMB. I think it is more related to an explosive device rather than a chemical itself. What do you think about COMPOUND being a stronger possibility than BOMB?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_5ktx', 'function': {'arguments': '{\"query\": \"I agree with you that COMPOUND is a stronger possibility than BOMB. I think we should guess COMPOUND first and see how it goes.\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}, {'id': 'call_528v', 'function': {'arguments': '{\"query\": \"COMPOUND\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 863, 'total_tokens': 928, 'completion_time': 0.26, 'prompt_time': 0.160217461, 'queue_time': 1.226397169, 'total_time': 0.420217461}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-0de5bcf8-2281-433e-a1f1-34b4e8a4e571-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree with you that COMPOUND is a stronger possibility than BOMB. I think we should guess COMPOUND first and see how it goes.'}, 'id': 'call_5ktx', 'type': 'tool_call'}, {'name': 'codenames_guess_tool', 'args': {'query': 'COMPOUND'}, 'id': 'call_528v', 'type': 'tool_call'}] usage_metadata={'input_tokens': 863, 'output_tokens': 65, 'total_tokens': 928}\n",
      "Correct! {'query': 'COMPOUND'} belongs to team blue.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 4_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " You said: 'I think the hint Chemical 2 could relate to OIL and COMPOUND, both are on the board and have a direct relation to chemicals. What do you think teammember_BLUE_1?'\n",
      "teammember_BLUE_1 said: 'I agree with you, OIL and COMPOUND are strong possibilities. I also think we should consider BOMB, as it can be a chemical explosive. What are your thoughts on BOMB?'\n",
      "You said: 'I agree with you on OIL and COMPOUND, but I am not sure about BOMB. I think it is more related to an explosive device rather than a chemical itself. What do you think about COMPOUND being a stronger possibility than BOMB?'\n",
      "teammember_BLUE_1 said: 'I agree with you that COMPOUND is a stronger possibility than BOMB. I think we should guess COMPOUND first and see how it goes.'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_tftb', 'function': {'arguments': '{\"query\": \"OIL\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 902, 'total_tokens': 920, 'completion_time': 0.072, 'prompt_time': 0.156825143, 'queue_time': 0.003542510999999998, 'total_time': 0.228825143}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-8f013eeb-ae43-4178-ae99-1dfab27cbd49-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'OIL'}, 'id': 'call_tftb', 'type': 'tool_call'}] usage_metadata={'input_tokens': 902, 'output_tokens': 18, 'total_tokens': 920}\n",
      "Incorrect! {'query': 'OIL'} is a red word.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "5_spymaster_RED hint: YOUNG 1\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 5_teammember_RED_2\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_736x', 'function': {'arguments': '{\"query\": \"I think the hint YOUNG applies to KID, what do you think?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 722, 'total_tokens': 755, 'completion_time': 0.132, 'prompt_time': 0.145004599, 'queue_time': 0.05803957699999998, 'total_time': 0.277004599}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-6ef79cbe-a93d-4863-a8dc-6c35e66a4fb0-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think the hint YOUNG applies to KID, what do you think?'}, 'id': 'call_736x', 'type': 'tool_call'}] usage_metadata={'input_tokens': 722, 'output_tokens': 33, 'total_tokens': 755}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 5_teammember_RED_1\n",
      "Current Discussion: \n",
      " teammember_RED_2 said: 'I think the hint YOUNG applies to KID, what do you think?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_v1zy', 'function': {'arguments': '{\"query\": \"I agree, KID is a strong candidate, but let me check if it has any direct relation to the hint YOUNG.\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}, {'id': 'call_64wn', 'function': {'arguments': '{\"query\": \"KID\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_gzm0', 'function': {'arguments': '{\"query\": \"\"}', 'name': 'codenames_end_turn_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 741, 'total_tokens': 816, 'completion_time': 0.3, 'prompt_time': 0.176106983, 'queue_time': 0.003819427000000014, 'total_time': 0.476106983}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-c40449f4-b4f6-42e2-b9b6-5f62d492a175-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree, KID is a strong candidate, but let me check if it has any direct relation to the hint YOUNG.'}, 'id': 'call_v1zy', 'type': 'tool_call'}, {'name': 'codenames_guess_tool', 'args': {'query': 'KID'}, 'id': 'call_64wn', 'type': 'tool_call'}, {'name': 'codenames_end_turn_tool', 'args': {'query': ''}, 'id': 'call_gzm0', 'type': 'tool_call'}] usage_metadata={'input_tokens': 741, 'output_tokens': 75, 'total_tokens': 816}\n",
      "Correct! {'query': 'KID'} belongs to team red.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "5_spymaster_BLUE hint: ANIMAL 1\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 5_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_6s8x', 'function': {'arguments': '{\"query\": \"I think the spymaster is hinting at a specific animal. Since the number is 1, I\\'m going to take a guess that the word is SHARK. What do you think, teammember_BLUE_2?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 704, 'total_tokens': 766, 'completion_time': 0.248, 'prompt_time': 0.1409856, 'queue_time': 0.003473751000000025, 'total_time': 0.3889856}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-a543ab33-d470-4f12-a819-7a8d87dabe71-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': \"I think the spymaster is hinting at a specific animal. Since the number is 1, I'm going to take a guess that the word is SHARK. What do you think, teammember_BLUE_2?\"}, 'id': 'call_6s8x', 'type': 'tool_call'}] usage_metadata={'input_tokens': 704, 'output_tokens': 62, 'total_tokens': 766}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 5_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " teammember_BLUE_1 said: 'I think the spymaster is hinting at a specific animal. Since the number is 1, I'm going to take a guess that the word is SHARK. What do you think, teammember_BLUE_2?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_t79q', 'function': {'arguments': '{\"query\": \"I agree, SHARK is a strong possibility, but we should also consider WORM as it is also an animal. What do you think about WORM?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 752, 'total_tokens': 800, 'completion_time': 0.192, 'prompt_time': 0.359814968, 'queue_time': 0.02123910000000001, 'total_time': 0.551814968}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-1bcf3607-b2c4-48d0-92aa-b373ccdf18d0-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree, SHARK is a strong possibility, but we should also consider WORM as it is also an animal. What do you think about WORM?'}, 'id': 'call_t79q', 'type': 'tool_call'}] usage_metadata={'input_tokens': 752, 'output_tokens': 48, 'total_tokens': 800}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 5_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " You said: 'I think the spymaster is hinting at a specific animal. Since the number is 1, I'm going to take a guess that the word is SHARK. What do you think, teammember_BLUE_2?'\n",
      "teammember_BLUE_2 said: 'I agree, SHARK is a strong possibility, but we should also consider WORM as it is also an animal. What do you think about WORM?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_2hgg', 'function': {'arguments': '{\"query\": \"I think SHARK is a stronger possibility than WORM, but I want to discuss further before making a guess. What do you think about the other words on the board, are there any other animals that could fit the hint?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 789, 'total_tokens': 851, 'completion_time': 0.248, 'prompt_time': 0.136166281, 'queue_time': 0.0037228089999999936, 'total_time': 0.384166281}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-3b47d49d-f9d6-409d-afd1-67fa315b2c87-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think SHARK is a stronger possibility than WORM, but I want to discuss further before making a guess. What do you think about the other words on the board, are there any other animals that could fit the hint?'}, 'id': 'call_2hgg', 'type': 'tool_call'}] usage_metadata={'input_tokens': 789, 'output_tokens': 62, 'total_tokens': 851}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 5_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " teammember_BLUE_1 said: 'I think the spymaster is hinting at a specific animal. Since the number is 1, I'm going to take a guess that the word is SHARK. What do you think, teammember_BLUE_2?'\n",
      "You said: 'I agree, SHARK is a strong possibility, but we should also consider WORM as it is also an animal. What do you think about WORM?'\n",
      "teammember_BLUE_1 said: 'I think SHARK is a stronger possibility than WORM, but I want to discuss further before making a guess. What do you think about the other words on the board, are there any other animals that could fit the hint?'\n",
      "Answer: \n",
      " <function=codenames_discuss_tool>{\"query\": \"I think we should also consider that there might be other animals on the board, but I couldn\"\n",
      "Test:content='<function=codenames_discuss_tool>{\"query\": \"I think we should also consider that there might be other animals on the board, but I couldn\"' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 845, 'total_tokens': 878, 'completion_time': 0.132, 'prompt_time': 0.167770615, 'queue_time': 0.0034257649999999973, 'total_time': 0.299770615}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'stop', 'logprobs': None} id='run-284dd2f2-9d72-4858-a2aa-a00f7a257d3b-0' usage_metadata={'input_tokens': 845, 'output_tokens': 33, 'total_tokens': 878}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 5_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " teammember_BLUE_1 said: 'I think the spymaster is hinting at a specific animal. Since the number is 1, I'm going to take a guess that the word is SHARK. What do you think, teammember_BLUE_2?'\n",
      "teammember_BLUE_2 said: 'I agree, SHARK is a strong possibility, but we should also consider WORM as it is also an animal. What do you think about WORM?'\n",
      "teammember_BLUE_1 said: 'I think SHARK is a stronger possibility than WORM, but I want to discuss further before making a guess. What do you think about the other words on the board, are there any other animals that could fit the hint?'\n",
      "Answer: \n",
      " <function=codenames_discuss_tool>{\"query\": \"I think we should also consider that there might be other animals on the board, but I couldn\"\n",
      "Test:content='<function=codenames_discuss_tool>{\"query\": \"I think we should also consider that there might be other animals on the board, but I couldn\"' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 871, 'total_tokens': 904, 'completion_time': 0.132, 'prompt_time': 0.166081503, 'queue_time': 0.003703629000000014, 'total_time': 0.298081503}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'stop', 'logprobs': None} id='run-7b4df267-d410-4182-a30c-dd257225787e-0' usage_metadata={'input_tokens': 871, 'output_tokens': 33, 'total_tokens': 904}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 5_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " teammember_BLUE_1 said: 'I think the spymaster is hinting at a specific animal. Since the number is 1, I'm going to take a guess that the word is SHARK. What do you think, teammember_BLUE_2?'\n",
      "teammember_BLUE_2 said: 'I agree, SHARK is a strong possibility, but we should also consider WORM as it is also an animal. What do you think about WORM?'\n",
      "teammember_BLUE_1 said: 'I think SHARK is a stronger possibility than WORM, but I want to discuss further before making a guess. What do you think about the other words on the board, are there any other animals that could fit the hint?'\n",
      "Answer: \n",
      " <function=codenames_discuss_tool>{\"query\": \"I think we should also consider that there might be other animals on the board, but I couldn\"\n",
      "Test:content='<function=codenames_discuss_tool>{\"query\": \"I think we should also consider that there might be other animals on the board, but I couldn\"' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 897, 'total_tokens': 930, 'completion_time': 0.132, 'prompt_time': 0.156174612, 'queue_time': 0.0036145680000000124, 'total_time': 0.288174612}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'stop', 'logprobs': None} id='run-1c8b89f7-c2fb-4614-99af-a9b9728d5496-0' usage_metadata={'input_tokens': 897, 'output_tokens': 33, 'total_tokens': 930}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 5_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " teammember_BLUE_1 said: 'I think the spymaster is hinting at a specific animal. Since the number is 1, I'm going to take a guess that the word is SHARK. What do you think, teammember_BLUE_2?'\n",
      "teammember_BLUE_2 said: 'I agree, SHARK is a strong possibility, but we should also consider WORM as it is also an animal. What do you think about WORM?'\n",
      "teammember_BLUE_1 said: 'I think SHARK is a stronger possibility than WORM, but I want to discuss further before making a guess. What do you think about the other words on the board, are there any other animals that could fit the hint?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_a2kh', 'function': {'arguments': '{\"query\": \"I think we should also consider the word THIEF, but it is not an animal. However, I do not see any other animals on the board that could fit the hint. I still think SHARK and WORM are our best options.\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 923, 'total_tokens': 989, 'completion_time': 0.264, 'prompt_time': 0.17510566, 'queue_time': 0.004166730000000007, 'total_time': 0.43910566}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-5ac054aa-d7a9-42d2-82cb-c1a1918a1a41-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think we should also consider the word THIEF, but it is not an animal. However, I do not see any other animals on the board that could fit the hint. I still think SHARK and WORM are our best options.'}, 'id': 'call_a2kh', 'type': 'tool_call'}] usage_metadata={'input_tokens': 923, 'output_tokens': 66, 'total_tokens': 989}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 5_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " You said: 'I think the spymaster is hinting at a specific animal. Since the number is 1, I'm going to take a guess that the word is SHARK. What do you think, teammember_BLUE_2?'\n",
      "teammember_BLUE_2 said: 'I agree, SHARK is a strong possibility, but we should also consider WORM as it is also an animal. What do you think about WORM?'\n",
      "You said: 'I think SHARK is a stronger possibility than WORM, but I want to discuss further before making a guess. What do you think about the other words on the board, are there any other animals that could fit the hint?'\n",
      "teammember_BLUE_2 said: 'I think we should also consider the word THIEF, but it is not an animal. However, I do not see any other animals on the board that could fit the hint. I still think SHARK and WORM are our best options.'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_4bmj', 'function': {'arguments': '{\"query\": \"SHARK\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 900, 'total_tokens': 918, 'completion_time': 0.072, 'prompt_time': 0.211692225, 'queue_time': 0.0036600149999999887, 'total_time': 0.283692225}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-fae6e644-f28e-403d-a3c8-9938db5e344b-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'SHARK'}, 'id': 'call_4bmj', 'type': 'tool_call'}] usage_metadata={'input_tokens': 900, 'output_tokens': 18, 'total_tokens': 918}\n",
      "Incorrect! {'query': 'SHARK'} is a neutral word.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "6_spymaster_RED hint: SUIT 2\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 6_teammember_RED_2\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_ak6r', 'function': {'arguments': '{\"query\": \"I think the hint SUIT could be related to a lawyer, what do you think?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 715, 'total_tokens': 749, 'completion_time': 0.136, 'prompt_time': 0.127383082, 'queue_time': 0.359044367, 'total_time': 0.263383082}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-e6dfeda6-c6e6-47ba-9cee-18dd70f94d75-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think the hint SUIT could be related to a lawyer, what do you think?'}, 'id': 'call_ak6r', 'type': 'tool_call'}] usage_metadata={'input_tokens': 715, 'output_tokens': 34, 'total_tokens': 749}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 6_teammember_RED_1\n",
      "Current Discussion: \n",
      " teammember_RED_2 said: 'I think the hint SUIT could be related to a lawyer, what do you think?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_ct14', 'function': {'arguments': '{\"query\": \"I agree, but we should also consider other possibilities like a business suit, which could be related to a ruler or a lawyer. What do you think about the word LAWYER?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 735, 'total_tokens': 788, 'completion_time': 0.212, 'prompt_time': 0.171196703, 'queue_time': 0.003705536999999981, 'total_time': 0.383196703}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-82019b7e-95da-4929-9c95-26b5f892a29b-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree, but we should also consider other possibilities like a business suit, which could be related to a ruler or a lawyer. What do you think about the word LAWYER?'}, 'id': 'call_ct14', 'type': 'tool_call'}] usage_metadata={'input_tokens': 735, 'output_tokens': 53, 'total_tokens': 788}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 6_teammember_RED_2\n",
      "Current Discussion: \n",
      " You said: 'I think the hint SUIT could be related to a lawyer, what do you think?'\n",
      "teammember_RED_1 said: 'I agree, but we should also consider other possibilities like a business suit, which could be related to a ruler or a lawyer. What do you think about the word LAWYER?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_jyes', 'function': {'arguments': '{\"query\": \"I think we should also consider the word RULER, but I think LAWYER is a stronger connection to the hint SUIT. What do you think about guessing LAWYER?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 777, 'total_tokens': 830, 'completion_time': 0.212, 'prompt_time': 0.145355237, 'queue_time': 0.0038486829999999916, 'total_time': 0.357355237}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-6b7ab377-b7a2-408b-927e-5f9b03d53d7f-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think we should also consider the word RULER, but I think LAWYER is a stronger connection to the hint SUIT. What do you think about guessing LAWYER?'}, 'id': 'call_jyes', 'type': 'tool_call'}] usage_metadata={'input_tokens': 777, 'output_tokens': 53, 'total_tokens': 830}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 6_teammember_RED_1\n",
      "Current Discussion: \n",
      " teammember_RED_2 said: 'I think the hint SUIT could be related to a lawyer, what do you think?'\n",
      "You said: 'I agree, but we should also consider other possibilities like a business suit, which could be related to a ruler or a lawyer. What do you think about the word LAWYER?'\n",
      "teammember_RED_2 said: 'I think we should also consider the word RULER, but I think LAWYER is a stronger connection to the hint SUIT. What do you think about guessing LAWYER?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_kbqa', 'function': {'arguments': '{\"query\": \"LAWYER\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_m5yy', 'function': {'arguments': '{\"query\": \"\"}', 'name': 'codenames_end_turn_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 824, 'total_tokens': 859, 'completion_time': 0.14, 'prompt_time': 0.151642988, 'queue_time': 0.0036436719999999867, 'total_time': 0.291642988}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-0377c3ea-b268-4256-a7d2-a27983761c63-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'LAWYER'}, 'id': 'call_kbqa', 'type': 'tool_call'}, {'name': 'codenames_end_turn_tool', 'args': {'query': ''}, 'id': 'call_m5yy', 'type': 'tool_call'}] usage_metadata={'input_tokens': 824, 'output_tokens': 35, 'total_tokens': 859}\n",
      "Correct! {'query': 'LAWYER'} belongs to team red.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "6_spymaster_BLUE hint: ANIMAL 1\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 6_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_w049', 'function': {'arguments': '{\"query\": \"What do you think about the spymaster\\'s hint ANIMAL 1? Any ideas which animal it could be?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 703, 'total_tokens': 743, 'completion_time': 0.16, 'prompt_time': 0.143044665, 'queue_time': 0.0020502250000000166, 'total_time': 0.303044665}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d49ce5d7-da2e-4b16-b938-01811c404a69-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': \"What do you think about the spymaster's hint ANIMAL 1? Any ideas which animal it could be?\"}, 'id': 'call_w049', 'type': 'tool_call'}] usage_metadata={'input_tokens': 703, 'output_tokens': 40, 'total_tokens': 743}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 6_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " teammember_BLUE_2 said: 'What do you think about the spymaster's hint ANIMAL 1? Any ideas which animal it could be?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_z2zm', 'function': {'arguments': '{\"query\": \"I think the spymaster is hinting at a WORM, since it is the only animal on the board.\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 729, 'total_tokens': 769, 'completion_time': 0.16, 'prompt_time': 0.141516801, 'queue_time': 0.003475898000000005, 'total_time': 0.301516801}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-cb1e8a9c-c012-4388-b3df-7beabe530d56-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think the spymaster is hinting at a WORM, since it is the only animal on the board.'}, 'id': 'call_z2zm', 'type': 'tool_call'}] usage_metadata={'input_tokens': 729, 'output_tokens': 40, 'total_tokens': 769}\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "GuessID: 6_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " You said: 'What do you think about the spymaster's hint ANIMAL 1? Any ideas which animal it could be?'\n",
      "teammember_BLUE_1 said: 'I think the spymaster is hinting at a WORM, since it is the only animal on the board.'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_3qyx', 'function': {'arguments': '{\"query\": \"WORM\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 758, 'total_tokens': 776, 'completion_time': 0.072, 'prompt_time': 0.129351309, 'queue_time': 0.0037858990000000092, 'total_time': 0.201351309}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-b165e2ff-4b7f-410e-9ff6-26a6801d436d-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'WORM'}, 'id': 'call_3qyx', 'type': 'tool_call'}] usage_metadata={'input_tokens': 758, 'output_tokens': 18, 'total_tokens': 776}\n",
      "Incorrect! {'query': 'WORM'} is a red word.\n",
      "guessed_words: PILOT, FLY, SKYSCRAPER, ICE CREAM, KID, BLOCK, IRON, CLOAK, GENIUS, SHARK, OIL, COMPOUND, LAWYER, STADIUM, WORM, IVORY, KETCHUP\n",
      "WINNER: RED\n",
      "ROUNDS PLAYED: 6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type CallbackManagerForToolRun is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# execute the game series\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgame_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[67], line 63\u001b[0m, in \u001b[0;36mGame_Series.run_series\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m board_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboard_random_states:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# print new board id centered in 50 dashes\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m BOARD ID: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m(board_id)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mcenter(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_1_round\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_results()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_statistics()\n",
      "Cell \u001b[0;32mIn[67], line 85\u001b[0m, in \u001b[0;36mGame_Series.run_1_round\u001b[0;34m(self, board_id)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# save game history\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[43mabot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/history_game_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mboard_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 40\u001b[0m, in \u001b[0;36mHistory.save\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     33\u001b[0m output \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboard\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboard,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwinner\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwinner\n\u001b[1;32m     37\u001b[0m }\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/json/encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type CallbackManagerForToolRun is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# execute the game series\n",
    "game_series.run_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Analysis entry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell after Running a series for a configuration to \n",
    "# calculate comparison measures\n",
    "result_df = pd.read_json(\"output_baseline/all_results_stats.json\") # Adapt to path of according output directory for configuration\n",
    "\n",
    "analysis_df = pd.read_excel('Analysis_Performance.xlsx')\n",
    "\n",
    "analysis_df.loc[len(analysis_df)] = [\n",
    "    result_df['config'][0],  \n",
    "    result_df['history'].apply(len).mean(), \n",
    "    result_df['guesses_red_correct'].mean(), \n",
    "    result_df['guesses_red_incorrect_black'].mean(), \n",
    "    result_df['guesses_red_incorrect_neutral'].mean(),  \n",
    "    result_df['guesses_red_incorrect_opponent'].mean(),  \n",
    "    result_df['guesses_red_incorrect_invalid'].mean(),  \n",
    "    result_df['guesses_blue_correct'].mean(),  \n",
    "    result_df['guesses_blue_incorrect_black'].mean(),  \n",
    "    result_df['guesses_blue_incorrect_neutral'].mean(),  \n",
    "    result_df['guesses_blue_incorrect_opponent'].mean(),  \n",
    "    result_df['guesses_blue_incorrect_invalid'].mean(),  \n",
    "    result_df['winner'].value_counts().idxmax(),  \n",
    "    (result_df['winner'].value_counts().max() / len(result_df)) * 100,  \n",
    "    (result_df['guesses_red_correct'].sum() / (  \n",
    "        result_df['guesses_red_correct'].sum() +\n",
    "        result_df['guesses_red_incorrect_black'].sum() +\n",
    "        result_df['guesses_red_incorrect_neutral'].sum() +\n",
    "        result_df['guesses_red_incorrect_opponent'].sum() +\n",
    "        result_df['guesses_red_incorrect_invalid'].sum()\n",
    "    )),\n",
    "    (result_df['guesses_blue_correct'].sum() / (  \n",
    "        result_df['guesses_blue_correct'].sum() +\n",
    "        result_df['guesses_blue_incorrect_black'].sum() +\n",
    "        result_df['guesses_blue_incorrect_neutral'].sum() +\n",
    "        result_df['guesses_blue_incorrect_opponent'].sum() +\n",
    "        result_df['guesses_blue_incorrect_invalid'].sum()\n",
    "    )),\n",
    "]\n",
    "\n",
    "analysis_df.to_excel('Analysis_Performance.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
