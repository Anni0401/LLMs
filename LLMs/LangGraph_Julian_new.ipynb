{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API Key loaded successfully\n",
      "Tavily API Key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if os.getenv(\"GROQ_API_KEY\"):\n",
    "    print('Groq API Key loaded successfully')\n",
    "else:\n",
    "    print('Groq API Key loading failed, please make sure the .env file exists and the spelling is correct')\n",
    "\n",
    "if os.getenv(\"TAVILY_API_KEY\"):\n",
    "    print('Tavily API Key loaded successfully')\n",
    "else:\n",
    "    print('Tavily API Key loading failed, please make sure the .env file exists and the spelling is correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "chat_model = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage, AIMessage, BaseMessage\n",
    "from langchain_groq import ChatGroq\n",
    "import random\n",
    "import copy\n",
    "from typing import Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.board = self.initialize_board()\n",
    "        self.red_words = [key for key, value in self.board.items() if value == \"red\"]\n",
    "        self.blue_words = [key for key, value in self.board.items() if value == \"blue\"]\n",
    "        self.black_words = [key for key, value in self.board.items() if value == \"black\"]\n",
    "        self.neutral_word = [key for key, value in self.board.items() if value == \"neutral\"]\n",
    "        self.has_turn = \"RED\"\n",
    "        self.winner = None\n",
    "        self.last_spymaster_answer = None\n",
    "        self.rounds = 0\n",
    "        self.guessed_words = set()\n",
    "        self.max_guesses = 1 # number of words to guess. Updated at every new spymaster clue\n",
    "        self.right_guesses = 0\n",
    "        self.wrong_guesses = 0\n",
    "        self.export_red = defaultdict(list)\n",
    "        self.export_blue = defaultdict(list)\n",
    "        self.current_turn = None\n",
    "\n",
    "    def initialize_board(self):\n",
    "        word_list = self.load_words()\n",
    "        board_words = random.sample(word_list, 25)\n",
    "        colors = [\"red\"] * 8 + [\"blue\"] * 8 + [\"neutral\"] * 7 + [\"black\"] * 2\n",
    "        random.shuffle(colors)\n",
    "        board = dict(zip(board_words, colors))\n",
    "        return board\n",
    "    \n",
    "    def load_words(self):\n",
    "        with open('wordlist-eng.txt', 'r') as file:\n",
    "            words = [line.strip() for line in file]\n",
    "            return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain.pydantic_v1 import BaseModel, Field, PrivateAttr\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "\n",
    "class GuessInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a single word from the game-board\")\n",
    "\n",
    "class GuessTool(BaseTool):\n",
    "    name: str = \"codenames_guess_tool\"\n",
    "    description: str = \"essential to guess words from the game-board\"\n",
    "    args_schema: Type[BaseModel] = GuessInput\n",
    "    game: Game = PrivateAttr()\n",
    "\n",
    "    def __init__(self, game):\n",
    "        super().__init__()\n",
    "        # Store the game object as an instance variable\n",
    "        self.game = game\n",
    "\n",
    "    def __call__(self, query: str) -> str:\n",
    "        \"\"\"Allows the tool to be callable directly.\"\"\"\n",
    "        return self._run(query)\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool with context from the game object.\"\"\"\n",
    "        query = query.upper()\n",
    "        if query in self.game.board.keys() and query not in self.game.guessed_words:\n",
    "            self.game.guessed_words.add(query)\n",
    "            return self.game.board[query]\n",
    "        else:\n",
    "            return f\"WRONG: {query}\"\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously with context from the game object.\"\"\"\n",
    "        raise NotImplementedError(\"custom_game_tool does not support async\")\n",
    "    \n",
    "\n",
    "class DiscussInput(BaseModel):\n",
    "    query: str = Field(description=\"should be the message for the teammembers\")\n",
    "\n",
    "class DiscussTool(BaseTool):\n",
    "    name: str = \"codenames_discuss_tool\"\n",
    "    description: str = \"essential to communicate with your teammembers\"\n",
    "    args_schema: Type[BaseModel] = DiscussInput\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, query: str) -> str:\n",
    "        \"\"\"Allows the tool to be callable directly.\"\"\"\n",
    "        return self._run(query)\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool to communicate with your teammembers, the query is the message.\"\"\"\n",
    "        return query    \n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously with context from the game object.\"\"\"\n",
    "        raise NotImplementedError(\"custom_game_tool does not support async\")\n",
    "    \n",
    "\n",
    "class RefrainTool(BaseTool):\n",
    "    name: str = \"codenames_refrain_tool\"\n",
    "    description: str = \"essential to refrain from interacting to let your teammembers interact\"\n",
    "    args_schema: Type[BaseModel] = DiscussInput\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, query=\"\") -> str:\n",
    "        \"\"\"Allows the tool to be callable directly.\"\"\"\n",
    "        return self._run(query)\n",
    "\n",
    "    def _run(\n",
    "        self, query, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool to refrain from interaction, to let your teammembers interact.\"\"\"\n",
    "        if query:\n",
    "            return query\n",
    "        else:\n",
    "            return \"Has refrained from interaction.\"    \n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously with context from the game object.\"\"\"\n",
    "        raise NotImplementedError(\"custom_game_tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, models: dict[str, dict[str, ChatGroq]], team_size=1, game=None, tools=None):\n",
    "        self.game = game\n",
    "        self.models = models\n",
    "        self.team_size = team_size\n",
    "        self.last_message_id = None\n",
    "\n",
    "        graph = StateGraph(AgentState)\n",
    "\n",
    "        # Setting up the nodes for the state graph\n",
    "        graph.add_node(\"spymaster_red\", self.call_red_spymaster)\n",
    "        graph.add_node(\"spymaster_blue\", self.call_blue_spymaster)\n",
    "        graph.add_node(\"teammember_red\", self.call_red_guesser)\n",
    "        graph.add_node(\"teammember_blue\", self.call_blue_guesser)\n",
    "        #graph.add_node(\"teammember_red_2\", self.call_red_guesser)\n",
    "        #graph.add_node(\"teammember_blue_2\", self.call_blue_guesser)\n",
    "        graph.add_node(\"action_red\", self.take_action)\n",
    "        graph.add_node(\"action_blue\", self.take_action)\n",
    "\n",
    "        # Conditional edges based on game state\n",
    "        graph.add_conditional_edges(\n",
    "             \"action_blue\",\n",
    "             self.define_next_player,\n",
    "             {0: END, 1: \"spymaster_red\", 2: \"teammember_blue\"}\n",
    "        )\n",
    "        graph.add_conditional_edges(\n",
    "             \"action_red\",\n",
    "             self.define_next_player,\n",
    "             {0: END, 1: \"spymaster_blue\", 2: \"teammember_red\"}\n",
    "        )\n",
    "\n",
    "        # Add edges for turn transitions\n",
    "        graph.add_edge(\"spymaster_red\", \"teammember_red\")\n",
    "        #graph.add_edge(\"teammember_red\", \"action_red\")\n",
    "        graph.add_edge(\"spymaster_blue\", \"teammember_blue\")\n",
    "        #graph.add_edge(\"teammember_blue\", \"action_blue\")\n",
    "        graph.set_entry_point(\"spymaster_red\")\n",
    "\n",
    "        # Conditional edges that check for presence of guessing action otherwise invoke next team member\n",
    "        graph.add_conditional_edges(\n",
    "            \"teammember_red\",\n",
    "            self.exists_tool_call,\n",
    "            {True: \"action_red\", False: \"teammember_red\"}\n",
    "        )\n",
    "        # graph.add_conditional_edges(\n",
    "        #     \"teammember_red_2\",\n",
    "        #     self.exists_tool_call,\n",
    "        #     {True: \"action_red\", False: \"teammember_red\"}\n",
    "        # )\n",
    "        graph.add_conditional_edges(\n",
    "            \"teammember_blue\",\n",
    "            self.exists_tool_call,\n",
    "            {True: \"action_blue\", False: \"teammember_blue\"}\n",
    "        )\n",
    "        # graph.add_conditional_edges(\n",
    "        #     \"teammember_blue_2\",\n",
    "        #     self.exists_tool_call,\n",
    "        #     {True: \"action_blue\", False: \"teammember_blue\"}\n",
    "        # )\n",
    "        \n",
    "        # Compile graph to LangChain Runnable\n",
    "        self.graph = graph.compile()\n",
    "        \n",
    "        # Bind tools to team member models if applicable\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        for name, model_dict in self.models.items():\n",
    "            if \"teammember\" in name:\n",
    "                model_dict[\"model\"] = model_dict[\"model\"].bind_tools(tools)\n",
    "\n",
    "\n",
    "    def define_next_player(self, state: AgentState):\n",
    "        exists_guess = self.exists_guess(state)\n",
    "        game_end = self.check_game_end(state)\n",
    "        if game_end:\n",
    "            return 0\n",
    "        elif exists_guess:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "    def exists_guess(self, state: AgentState):\n",
    "        # TODO: REWRITE: message in this case is Toolmessage\n",
    "        # Assuming `messages` is your list of Message objects\n",
    "        last_tool_messages = []\n",
    "        messages = state['messages']\n",
    "        index = len(messages) - 1\n",
    "        # Step 2: Collect ToolMessages until we encounter a non-ToolMessage\n",
    "        while index >= 0:\n",
    "            message = messages[index]\n",
    "            if isinstance(message, ToolMessage):\n",
    "                last_tool_messages.append(message)\n",
    "            else:\n",
    "                # Stop if we encounter a non-ToolMessage type\n",
    "                break\n",
    "            index -= 1\n",
    "        was_guessed = any(m.name == \"codenames_guess_tool\" for m in last_tool_messages)\n",
    "        return was_guessed\n",
    "    \n",
    "    def exists_tool_call(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        print(f\"Test:{result}\")\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    \n",
    "    # def exists_guess(self, state: AgentState):\n",
    "    #     result = state['messages'][-1]\n",
    "    #     # Check if the team member has made a deliberation before using the tool\n",
    "    #     deliberation_message = \"deliberated\"\n",
    "    #     deliberated = deliberation_message in result.content\n",
    "    #     return len(result.tool_calls) > 0 and deliberated\n",
    "            \n",
    "    def call_red_spymaster(self, state: AgentState):\n",
    "        return self._call_spymaster(\"RED\", state)\n",
    "\n",
    "    def call_blue_spymaster(self, state: AgentState):\n",
    "        return self._call_spymaster(\"BLUE\", state)\n",
    "\n",
    "    def call_red_guesser(self, state: AgentState):\n",
    "        number = random.randint(1,self.team_size)\n",
    "        return self._call_guesser(\"RED\", number, state)\n",
    "\n",
    "    def call_blue_guesser(self, state: AgentState):\n",
    "        number = random.randint(1,self.team_size)\n",
    "        return self._call_guesser(\"BLUE\", number, state)\n",
    "    \n",
    "    def check_game_end(self, state: AgentState):\n",
    "        game_over = False\n",
    "        if self.game.rounds > 5:\n",
    "            game_over = True\n",
    "        game_ends_black = any(word in self.game.guessed_words for word in self.game.black_words)\n",
    "        game_ends_red = all(word in self.game.guessed_words for word in self.game.red_words)\n",
    "        game_ends_blue = all(word in self.game.guessed_words for word in self.game.blue_words)\n",
    "        if game_ends_black or game_ends_red or game_ends_blue:\n",
    "            game_over = True\n",
    "        if game_ends_black:\n",
    "            self.game.winner = \"BLUE\" if self.game.has_turn == \"RED\" else \"RED\"\n",
    "        elif game_ends_red:\n",
    "            self.game.winner = \"RED\"\n",
    "        elif game_ends_blue:\n",
    "            self.game.winner = \"BLUE\"\n",
    "        \n",
    "        if game_over:\n",
    "            print(f\"guessed_words: {', '.join(self.game.guessed_words)}\")\n",
    "            print(f\"WINNER: {self.game.winner}\")\n",
    "            print(f\"ROUNDS PLAYED: {self.game.rounds}\")\n",
    "            \n",
    "            export = f\"\"\"WINNER: {self.game.winner} , \n",
    "            BOARD:  {self.game.board} , \n",
    "            Guesses RED:{self.game.export_red} , \n",
    "            Guesses BLUE:{self.game.export_blue} , \n",
    "            Right Guesses {self.game.right_guesses}, \n",
    "            Wrong Guesses {self.game.wrong_guesses}\"\"\"\n",
    "            with open(\"output_game.txt\", \"w\") as file:\n",
    "                file.write(export)\n",
    "\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state.get('messages', [])[-1].tool_calls\n",
    "        results = []\n",
    "        guesses = 0\n",
    "        for t in tool_calls:\n",
    "            if t[\"name\"]=='codenames_guess_tool':\n",
    "                if self.game.has_turn.lower() == 'red':\n",
    "                    self.game.export_red[self.game.last_spymaster_answer.content].append(str(t['args']))\n",
    "                else:\n",
    "                    self.game.export_blue[str(self.game.last_spymaster_answer.content)].append(str(t['args']))\n",
    "        for t in tool_calls:\n",
    "            if t[\"name\"]=='codenames_guess_tool':\n",
    "                if guesses >= self.game.max_guesses:\n",
    "                    break\n",
    "                if t['name'] in self.tools:\n",
    "                    result = self.tools[t['name']].invoke(t['args'])\n",
    "                    guessed_word_color = result.lower()\n",
    "                    guesses += 1\n",
    "                    results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result))) \n",
    "                    \n",
    "                    # Check the result to determine if the turn should end\n",
    "                    if guessed_word_color == self.game.has_turn.lower():\n",
    "                        # Correct guess, team can continue if max_guesses not reached\n",
    "                        self.game.right_guesses  = self.game.right_guesses +1\n",
    "                        print(f\"Correct! {t['args']} belongs to team {guessed_word_color}.\")\n",
    "                    elif guessed_word_color == \"black\":\n",
    "                        #End game, other team wins\n",
    "                        print(f\"Black word guessed! {self.game.has_turn} loses.\")\n",
    "                        break\n",
    "                    else:\n",
    "                        # Neutral or opponent's word, end turn\n",
    "                        self.game.wrong_guesses = self.game.wrong_guesses +1\n",
    "                        print(f\"Incorrect! {t['args']} is a {guessed_word_color} word.\")\n",
    "                        break\n",
    "                else:\n",
    "                    results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=\"Invalid tool name, retry\"))\n",
    "            elif t[\"name\"] == 'codenames_discuss_tool' or t[\"name\"] == 'codenames_refrain_tool':\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "                results.append(ToolMessage(id=self.last_message_id, tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "            else:\n",
    "                results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=\"Invalid tool name, retry\"))\n",
    "\n",
    "           \n",
    "        return {'messages': results}\n",
    "    \n",
    "    def _call_spymaster(self, team, state):\n",
    "        self.game.rounds += 1\n",
    "        self.game.has_turn = team.upper()\n",
    "        round = self.game.rounds\n",
    "        messages = state['messages']\n",
    "        prompt = self.get_spymaster_prompt(team)\n",
    "        model = self.models[f\"spymaster_{team}\"][\"model\"]\n",
    "        message = model.invoke(prompt)\n",
    "        message.id = f\"{round}_spymaster_{team}\"\n",
    "        # Parse the hint number from the spymaster's message (assuming format \"Word N\")\n",
    "        hint_text = message.content.split()\n",
    "        self.game.max_guesses = int(hint_text[1]) if len(hint_text) > 1 and hint_text[1].isdigit() else 1\n",
    "        #state['messages'].append(message)\n",
    "        self.game.last_spymaster_answer = message\n",
    "        self.game.current_turn = f\"{round}_spymaster_{team}\"\n",
    "        return {'messages': [message]}\n",
    "    \n",
    "    def _call_guesser(self, team, number, state):\n",
    "        round = self.game.rounds\n",
    "        messages = state['messages']\n",
    "        prompt = self.get_guesser_prompt(team, number)[0].content\n",
    "        \n",
    "        # Retrieve spymaster's hint and prepare discussion string\n",
    "        spymaster_message = self.get_message_by_id(messages, f\"{round}_spymaster_{team}\")\n",
    "        spymaster_hint = f\"Spymaster's hint: {spymaster_message if spymaster_message else 'No hint available'} \\n\"\n",
    "        filtered_messages = [m for m in messages if m.id is not None and m.id.startswith(f\"{round}_teammember_{team}\")]\n",
    "        current_discussion_string = \"\\n\".join(f\"{m.id[2:]} said: '{m.content.strip()}'\" for m in filtered_messages if m.id is not None)\n",
    "        if current_discussion_string == \"\":\n",
    "            current_discussion_string = \"No discussion has taken place yet.\"\n",
    "\n",
    "        team_members = [f\"teammember_{team}_{i + 1}\" for i in range(self.team_size)]\n",
    "        team_members.remove(f\"teammember_{team}_{number}\")\n",
    "        team_members_string = f\"Your team members are: {', '.join(team_members)}.\"\n",
    "        you_string = f\"You are teammember_{team}_{number}.\"\n",
    "        self.last_message_id = f\"{round}_teammember_{team}_{number}\"\n",
    "        \n",
    "        # Combine into new_prompt\n",
    "        current_discussion_string = current_discussion_string.replace(f\"teammember_{team}_{number} said:\", \"You said:\")\n",
    "        new_prompt_content = (\n",
    "            prompt\n",
    "            + \"\\n\"\n",
    "            + spymaster_hint\n",
    "            + you_string + \"\\n\"\n",
    "            + team_members_string + \"\\n\"\n",
    "            + f\"\\nThis is the current discussion with your Teammembers:\"\n",
    "            + \"\\n\"\n",
    "            + current_discussion_string\n",
    "        )\n",
    "\n",
    "\n",
    "        model = self.models[f\"teammember_{team}_{number}\"][\"model\"]\n",
    "        message = model.invoke([new_prompt_content])  # Pass as a single-item list containing the BaseMessage instance\n",
    "        \n",
    "        # Set message ID and append\n",
    "        #message.id = f\"{round}_teammember_{team}_{number}\"\n",
    "        #state['messages'].append(message)\n",
    "        print(f\"GuessID: {round}_teammember_{team}_{number}\")\n",
    "        print(f\"Current Discussion: \\n {current_discussion_string}\")\n",
    "        print(f\"Answer: \\n {message.content}\")  # Display prompt content for verification\n",
    "        \n",
    "        return {'messages': [message]}\n",
    "        \n",
    "    def get_spymaster_prompt(self, team):\n",
    "        not_guessed_board = {k: v for k, v in self.game.board.items() if k not in self.game.guessed_words}\n",
    "        relevant_words = [k for k, v in not_guessed_board.items() if v.lower() == team.lower()]\n",
    "        bad_words = [k for k, v in not_guessed_board.items() if v.lower() != team.lower()]\n",
    "        \n",
    "        return [SystemMessage(content=self.models[f\"spymaster_{team}\"][\"system\"]\n",
    "            + f\"\\nGood words: {', '.join(relevant_words)}\\n\"\n",
    "            + f\"Bad words: {', '.join(bad_words)}\"\n",
    "        )]\n",
    "    \n",
    "    def get_guesser_prompt(self, team, number):\n",
    "        not_guessed_board = [k for k in self.game.board if k not in self.game.guessed_words]\n",
    "        hint_word = self.game.last_spymaster_answer.content\n",
    "\n",
    "        return [SystemMessage(content=self.models[f\"teammember_{team}_{number}\"][\"system\"]\n",
    "            + f\"\\nWord list: {', '.join(not_guessed_board)}\\n\"\n",
    "            + f\"Hint word: {hint_word}\"\n",
    "        )]\n",
    "    \n",
    "    def get_message_by_id(self, messages, target_id):\n",
    "        for message in messages:\n",
    "            if message.id == target_id:\n",
    "                return message.content\n",
    "        return None  # Return None if no message with the given id is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompt_from_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        prompt = file.read()  # Reads the entire content of the file as a string\n",
    "    return prompt\n",
    "\n",
    "\n",
    "spymaster_system_prompt =  load_prompt_from_file('spymaster_system_prompt.txt')\n",
    "\n",
    "teammember_system_prompt = \"\"\"\n",
    "    You are a team member in the game Codenames. Each round, your spymaster will give a one-word hint and a number. Your goal is to guess the target words based on this hint.\n",
    "\n",
    "    1. Use the hint word to find words that semantically relate to the target, based on the spymaster’s clue.\n",
    "    2. The number indicates how many words the hint likely applies to. Keep this in mind while choosing words.\n",
    "    3. Discuss and collaborate with me and the other team members to reach a consensus before making each guess.\n",
    "    4. Do NOT use the guessing tool if you have not yet deliberated with everyone else.\n",
    "    5. If you do not use the guessing tool, reason shortly and precisely so your team can benefit from your insights.\n",
    "    6. Use the provided guessing tool to submit each guess. If correct, you may guess again until the number limit is reached or an incorrect guess is made.\n",
    "\n",
    "    Each guess brings your team closer to victory, but beware—incorrect guesses may help the opposing team! And don't forget: be social and deliberate!\n",
    "\"\"\"\n",
    "\n",
    "teammember_system_prompt =  load_prompt_from_file('teammember_system_prompt.txt')\n",
    "\n",
    "models = {\n",
    "    \"spymaster_RED\": {\"model\": None, \"system\": spymaster_system_prompt},\n",
    "    \"spymaster_BLUE\": {\"model\": None, \"system\": spymaster_system_prompt},\n",
    "    \"teammember_RED_1\": {\"model\": None, \"system\": teammember_system_prompt},\n",
    "    \"teammember_BLUE_1\": {\"model\": None, \"system\": teammember_system_prompt},\n",
    "    \"teammember_RED_2\": {\"model\": None, \"system\": teammember_system_prompt},\n",
    "    \"teammember_BLUE_2\": {\"model\": None, \"system\": teammember_system_prompt},\n",
    "}\n",
    "\n",
    "for name, model_dict in models.items():\n",
    "    if \"spymaster\" in name:\n",
    "        model_dict[\"model\"] = ChatGroq(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        temperature=0,\n",
    "        max_tokens=20,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        )   \n",
    "    else:\n",
    "        model_dict[\"model\"] = ChatGroq(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        abot.graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GuessID: 1_teammember_RED_1\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_tw77', 'function': {'arguments': '{\"query\": \"What are your thoughts on the hint WATER, any ideas which words might be related?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 815, 'total_tokens': 848, 'completion_time': 0.132, 'prompt_time': 0.180559752, 'queue_time': 0.0035164609999999985, 'total_time': 0.312559752}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-3cc1e1da-88f4-40dd-876e-b219a6520d7d-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'What are your thoughts on the hint WATER, any ideas which words might be related?'}, 'id': 'call_tw77', 'type': 'tool_call'}] usage_metadata={'input_tokens': 815, 'output_tokens': 33, 'total_tokens': 848}\n",
      "GuessID: 1_teammember_RED_2\n",
      "Current Discussion: \n",
      " teammember_RED_1 said: 'What are your thoughts on the hint WATER, any ideas which words might be related?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_29z7', 'function': {'arguments': '{\"query\": \"I think the words WAVE, OIL, and possibly WHALE could be related to WATER. What do you think?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 834, 'total_tokens': 875, 'completion_time': 0.164, 'prompt_time': 0.141867797, 'queue_time': 0.0040690030000000155, 'total_time': 0.305867797}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-dc28a07b-f9d7-4aea-9cf3-2e39aa07cd7a-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think the words WAVE, OIL, and possibly WHALE could be related to WATER. What do you think?'}, 'id': 'call_29z7', 'type': 'tool_call'}] usage_metadata={'input_tokens': 834, 'output_tokens': 41, 'total_tokens': 875}\n",
      "GuessID: 1_teammember_RED_1\n",
      "Current Discussion: \n",
      " You said: 'What are your thoughts on the hint WATER, any ideas which words might be related?'\n",
      "teammember_RED_2 said: 'I think the words WAVE, OIL, and possibly WHALE could be related to WATER. What do you think?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_fp17', 'function': {'arguments': '{\"query\": \"I agree with WAVE and WHALE, but I am not sure about OIL. What about words like MOUTH or HEART, could they be related to WATER in some way?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 864, 'total_tokens': 918, 'completion_time': 0.216, 'prompt_time': 0.155756376, 'queue_time': 0.0032915000000000028, 'total_time': 0.371756376}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-61920b3d-50b6-408e-9aec-0412e8ec4676-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I agree with WAVE and WHALE, but I am not sure about OIL. What about words like MOUTH or HEART, could they be related to WATER in some way?'}, 'id': 'call_fp17', 'type': 'tool_call'}] usage_metadata={'input_tokens': 864, 'output_tokens': 54, 'total_tokens': 918}\n",
      "GuessID: 1_teammember_RED_1\n",
      "Current Discussion: \n",
      " You said: 'What are your thoughts on the hint WATER, any ideas which words might be related?'\n",
      "teammember_RED_2 said: 'I think the words WAVE, OIL, and possibly WHALE could be related to WATER. What do you think?'\n",
      "You said: 'I agree with WAVE and WHALE, but I am not sure about OIL. What about words like MOUTH or HEART, could they be related to WATER in some way?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_hkzz', 'function': {'arguments': '{\"query\": \"I think we should focus on WAVE and WHALE for now, but I also want to consider other options like MOUNT or BATTERY, do you think they could be related to WATER?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 907, 'total_tokens': 962, 'completion_time': 0.22, 'prompt_time': 0.168313351, 'queue_time': 0.004062082999999994, 'total_time': 0.388313351}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-3f687fcf-70ea-44e7-b4f1-dfe9b0add430-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think we should focus on WAVE and WHALE for now, but I also want to consider other options like MOUNT or BATTERY, do you think they could be related to WATER?'}, 'id': 'call_hkzz', 'type': 'tool_call'}] usage_metadata={'input_tokens': 907, 'output_tokens': 55, 'total_tokens': 962}\n",
      "GuessID: 1_teammember_RED_2\n",
      "Current Discussion: \n",
      " teammember_RED_1 said: 'What are your thoughts on the hint WATER, any ideas which words might be related?'\n",
      "You said: 'I think the words WAVE, OIL, and possibly WHALE could be related to WATER. What do you think?'\n",
      "teammember_RED_1 said: 'I agree with WAVE and WHALE, but I am not sure about OIL. What about words like MOUTH or HEART, could they be related to WATER in some way?'\n",
      "teammember_RED_1 said: 'I think we should focus on WAVE and WHALE for now, but I also want to consider other options like MOUNT or BATTERY, do you think they could be related to WATER?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_4w0e', 'function': {'arguments': '{\"query\": \"I think MOUNT could be related to WATER as in a mountain near a lake or river, but I am not sure about BATTERY. What about CENTER, could it be related to WATER in some way?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 961, 'total_tokens': 1019, 'completion_time': 0.232, 'prompt_time': 0.178428129, 'queue_time': 0.003026996000000004, 'total_time': 0.410428129}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-29118a44-7d0a-456e-872b-b459e6723bdd-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think MOUNT could be related to WATER as in a mountain near a lake or river, but I am not sure about BATTERY. What about CENTER, could it be related to WATER in some way?'}, 'id': 'call_4w0e', 'type': 'tool_call'}] usage_metadata={'input_tokens': 961, 'output_tokens': 58, 'total_tokens': 1019}\n",
      "GuessID: 1_teammember_RED_2\n",
      "Current Discussion: \n",
      " teammember_RED_1 said: 'What are your thoughts on the hint WATER, any ideas which words might be related?'\n",
      "You said: 'I think the words WAVE, OIL, and possibly WHALE could be related to WATER. What do you think?'\n",
      "teammember_RED_1 said: 'I agree with WAVE and WHALE, but I am not sure about OIL. What about words like MOUTH or HEART, could they be related to WATER in some way?'\n",
      "teammember_RED_1 said: 'I think we should focus on WAVE and WHALE for now, but I also want to consider other options like MOUNT or BATTERY, do you think they could be related to WATER?'\n",
      "You said: 'I think MOUNT could be related to WATER as in a mountain near a lake or river, but I am not sure about BATTERY. What about CENTER, could it be related to WATER in some way?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_gm2g', 'function': {'arguments': '{\"query\": \"I think we should focus on WAVE and WHALE for now, and also consider MOUNT and possibly CENTER, but I am not sure about BATTERY, what do you think about these options?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1008, 'total_tokens': 1064, 'completion_time': 0.224, 'prompt_time': 0.19988385, 'queue_time': 0.003413685999999999, 'total_time': 0.42388385}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-fe4611b3-57fe-415a-8252-ae496b24fec5-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think we should focus on WAVE and WHALE for now, and also consider MOUNT and possibly CENTER, but I am not sure about BATTERY, what do you think about these options?'}, 'id': 'call_gm2g', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1008, 'output_tokens': 56, 'total_tokens': 1064}\n",
      "GuessID: 1_teammember_RED_1\n",
      "Current Discussion: \n",
      " You said: 'What are your thoughts on the hint WATER, any ideas which words might be related?'\n",
      "teammember_RED_2 said: 'I think the words WAVE, OIL, and possibly WHALE could be related to WATER. What do you think?'\n",
      "You said: 'I agree with WAVE and WHALE, but I am not sure about OIL. What about words like MOUTH or HEART, could they be related to WATER in some way?'\n",
      "You said: 'I think we should focus on WAVE and WHALE for now, but I also want to consider other options like MOUNT or BATTERY, do you think they could be related to WATER?'\n",
      "teammember_RED_2 said: 'I think MOUNT could be related to WATER as in a mountain near a lake or river, but I am not sure about BATTERY. What about CENTER, could it be related to WATER in some way?'\n",
      "teammember_RED_2 said: 'I think we should focus on WAVE and WHALE for now, and also consider MOUNT and possibly CENTER, but I am not sure about BATTERY, what do you think about these options?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_apyh', 'function': {'arguments': '{\"query\": \"WAVE\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_e4s0', 'function': {'arguments': '{\"query\": \"WHALE\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_9n8j', 'function': {'arguments': '{\"query\": \"I think we should guess WAVE and WHALE first, and then consider MOUNT and CENTER. What do you think about guessing MOUNT next?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 1053, 'total_tokens': 1134, 'completion_time': 0.324, 'prompt_time': 0.18063285, 'queue_time': 0.0037069129999999784, 'total_time': 0.50463285}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-0de3443a-9c97-4384-9058-ea3df253f4cd-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'WAVE'}, 'id': 'call_apyh', 'type': 'tool_call'}, {'name': 'codenames_guess_tool', 'args': {'query': 'WHALE'}, 'id': 'call_e4s0', 'type': 'tool_call'}, {'name': 'codenames_discuss_tool', 'args': {'query': 'I think we should guess WAVE and WHALE first, and then consider MOUNT and CENTER. What do you think about guessing MOUNT next?'}, 'id': 'call_9n8j', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1053, 'output_tokens': 81, 'total_tokens': 1134}\n",
      "Correct! {'query': 'WAVE'} belongs to team red.\n",
      "Correct! {'query': 'WHALE'} belongs to team red.\n",
      "GuessID: 2_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_82y7', 'function': {'arguments': '{\"query\": \"What words on the board relate to geometry?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 811, 'total_tokens': 836, 'completion_time': 0.1, 'prompt_time': 0.154111477, 'queue_time': 0.003390782000000009, 'total_time': 0.254111477}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-302ee104-4567-406f-bf03-055686f8f811-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'What words on the board relate to geometry?'}, 'id': 'call_82y7', 'type': 'tool_call'}] usage_metadata={'input_tokens': 811, 'output_tokens': 25, 'total_tokens': 836}\n",
      "GuessID: 2_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " You said: 'What words on the board relate to geometry?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_as10', 'function': {'arguments': '{\"query\": \"Waiting for teammember_BLUE_2 to respond.\"}', 'name': 'codenames_refrain_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 817, 'total_tokens': 843, 'completion_time': 0.104, 'prompt_time': 0.139481108, 'queue_time': 0.0037695010000000084, 'total_time': 0.243481108}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-2cc9c511-e9c6-4c93-94d2-ff73fc73472b-0' tool_calls=[{'name': 'codenames_refrain_tool', 'args': {'query': 'Waiting for teammember_BLUE_2 to respond.'}, 'id': 'call_as10', 'type': 'tool_call'}] usage_metadata={'input_tokens': 817, 'output_tokens': 26, 'total_tokens': 843}\n",
      "GuessID: 2_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " You said: 'What words on the board relate to geometry?'\n",
      "You said: 'Waiting for teammember_BLUE_2 to respond.'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_scn7', 'function': {'arguments': '{\"query\": \"Waiting for teammember_BLUE_2 to respond.\"}', 'name': 'codenames_refrain_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 832, 'total_tokens': 858, 'completion_time': 0.104, 'prompt_time': 0.148921294, 'queue_time': 0.0034370739999999844, 'total_time': 0.252921294}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-e5e391d8-2535-472b-9ef7-d3fab0d2add5-0' tool_calls=[{'name': 'codenames_refrain_tool', 'args': {'query': 'Waiting for teammember_BLUE_2 to respond.'}, 'id': 'call_scn7', 'type': 'tool_call'}] usage_metadata={'input_tokens': 832, 'output_tokens': 26, 'total_tokens': 858}\n",
      "GuessID: 2_teammember_BLUE_2\n",
      "Current Discussion: \n",
      " teammember_BLUE_1 said: 'What words on the board relate to geometry?'\n",
      "teammember_BLUE_1 said: 'Waiting for teammember_BLUE_2 to respond.'\n",
      "teammember_BLUE_1 said: 'Waiting for teammember_BLUE_2 to respond.'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_njfk', 'function': {'arguments': '{\"query\": \"I think SQUARE, CENTER, and MOUNT relate to geometry.\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 861, 'total_tokens': 890, 'completion_time': 0.116, 'prompt_time': 0.154542837, 'queue_time': 0.003522522, 'total_time': 0.270542837}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-29007945-d862-43dc-8c91-b4b1c210416e-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think SQUARE, CENTER, and MOUNT relate to geometry.'}, 'id': 'call_njfk', 'type': 'tool_call'}] usage_metadata={'input_tokens': 861, 'output_tokens': 29, 'total_tokens': 890}\n",
      "GuessID: 2_teammember_BLUE_1\n",
      "Current Discussion: \n",
      " You said: 'What words on the board relate to geometry?'\n",
      "You said: 'Waiting for teammember_BLUE_2 to respond.'\n",
      "You said: 'Waiting for teammember_BLUE_2 to respond.'\n",
      "teammember_BLUE_2 said: 'I think SQUARE, CENTER, and MOUNT relate to geometry.'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_kspg', 'function': {'arguments': '{\"query\": \"SQUARE\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_76dy', 'function': {'arguments': '{\"query\": \"CENTER\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}, {'id': 'call_nzgf', 'function': {'arguments': '{\"query\": \"MOUNT\"}', 'name': 'codenames_guess_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 868, 'total_tokens': 919, 'completion_time': 0.204, 'prompt_time': 0.147195961, 'queue_time': 0.0037490690000000215, 'total_time': 0.351195961}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-eb2067c3-4ef5-4942-a677-39bc2a80a4d4-0' tool_calls=[{'name': 'codenames_guess_tool', 'args': {'query': 'SQUARE'}, 'id': 'call_kspg', 'type': 'tool_call'}, {'name': 'codenames_guess_tool', 'args': {'query': 'CENTER'}, 'id': 'call_76dy', 'type': 'tool_call'}, {'name': 'codenames_guess_tool', 'args': {'query': 'MOUNT'}, 'id': 'call_nzgf', 'type': 'tool_call'}] usage_metadata={'input_tokens': 868, 'output_tokens': 51, 'total_tokens': 919}\n",
      "Correct! {'query': 'SQUARE'} belongs to team blue.\n",
      "Correct! {'query': 'CENTER'} belongs to team blue.\n",
      "Incorrect! {'query': 'MOUNT'} is a neutral word.\n",
      "GuessID: 3_teammember_RED_1\n",
      "Current Discussion: \n",
      " No discussion has taken place yet.\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_b7fb', 'function': {'arguments': '{\"query\": \"What are your thoughts on the hint FIGHT?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 800, 'total_tokens': 826, 'completion_time': 0.104, 'prompt_time': 0.160996915, 'queue_time': 0.0038346939999999996, 'total_time': 0.264996915}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-593027d1-aace-4213-85ff-4c0f250a9cb1-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'What are your thoughts on the hint FIGHT?'}, 'id': 'call_b7fb', 'type': 'tool_call'}] usage_metadata={'input_tokens': 800, 'output_tokens': 26, 'total_tokens': 826}\n",
      "GuessID: 3_teammember_RED_1\n",
      "Current Discussion: \n",
      " You said: 'What are your thoughts on the hint FIGHT?'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_13st', 'function': {'arguments': '{\"query\": \"Waiting for teammember_RED_2 to respond\"}', 'name': 'codenames_refrain_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 807, 'total_tokens': 833, 'completion_time': 0.104, 'prompt_time': 0.169002138, 'queue_time': 0.003626968000000008, 'total_time': 0.273002138}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-e40428a0-b705-48e6-be05-35879912e6b2-0' tool_calls=[{'name': 'codenames_refrain_tool', 'args': {'query': 'Waiting for teammember_RED_2 to respond'}, 'id': 'call_13st', 'type': 'tool_call'}] usage_metadata={'input_tokens': 807, 'output_tokens': 26, 'total_tokens': 833}\n",
      "GuessID: 3_teammember_RED_2\n",
      "Current Discussion: \n",
      " teammember_RED_1 said: 'What are your thoughts on the hint FIGHT?'\n",
      "teammember_RED_1 said: 'Waiting for teammember_RED_2 to respond'\n",
      "Answer: \n",
      " \n",
      "Test:content='' additional_kwargs={'tool_calls': [{'id': 'call_mmtp', 'function': {'arguments': '{\"query\": \"I think the hint FIGHT could relate to words like FIGHTER, NINJA, or BAT. What do you think?\"}', 'name': 'codenames_discuss_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 832, 'total_tokens': 875, 'completion_time': 0.172, 'prompt_time': 0.151632304, 'queue_time': 0.005717004999999997, 'total_time': 0.323632304}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-997d8f1f-4c41-421d-bc66-799f3b943a6d-0' tool_calls=[{'name': 'codenames_discuss_tool', 'args': {'query': 'I think the hint FIGHT could relate to words like FIGHTER, NINJA, or BAT. What do you think?'}, 'id': 'call_mmtp', 'type': 'tool_call'}] usage_metadata={'input_tokens': 832, 'output_tokens': 43, 'total_tokens': 875}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/groq/_base_client.py:1018\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1018\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/httpx/_models.py:763\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 763\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m abot \u001b[38;5;241m=\u001b[39m Agent(models, team_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, game\u001b[38;5;241m=\u001b[39mgame, tools\u001b[38;5;241m=\u001b[39m[game_tool, discuss_tool, refrain_tool])\n\u001b[1;32m      7\u001b[0m messages \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlay a game of Codenames.\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mabot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecursion_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1569\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1568\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1569\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1307\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1302\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   1303\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   1304\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   1305\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1306\u001b[0m     ):\n\u001b[0;32m-> 1307\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1314\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langgraph/pregel/runner.py:56\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m     54\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langgraph/pregel/retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langgraph/utils/runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[31], line 121\u001b[0m, in \u001b[0;36mAgent.call_red_guesser\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_red_guesser\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: AgentState):\n\u001b[1;32m    120\u001b[0m     number \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteam_size)\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_guesser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRED\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 256\u001b[0m, in \u001b[0;36mAgent._call_guesser\u001b[0;34m(self, team, number, state)\u001b[0m\n\u001b[1;32m    243\u001b[0m new_prompt_content \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    244\u001b[0m     prompt\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;241m+\u001b[39m current_discussion_string\n\u001b[1;32m    252\u001b[0m )\n\u001b[1;32m    255\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteammember_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 256\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_prompt_content\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass as a single-item list containing the BaseMessage instance\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Set message ID and append\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m#message.id = f\"{round}_teammember_{team}_{number}\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m#state['messages'].append(message)\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGuessID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_teammember_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langchain_core/runnables/base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    285\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    647\u001b[0m ]\n\u001b[1;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m         )\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/langchain_groq/chat_models.py:473\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    469\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    472\u001b[0m }\n\u001b[0;32m--> 473\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/groq/resources/chat/completions.py:287\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/groq/_base_client.py:1244\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1232\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1240\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1241\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1242\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1243\u001b[0m     )\n\u001b[0;32m-> 1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/groq/_base_client.py:936\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/groq/_base_client.py:1024\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1023\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/groq/_base_client.py:1071\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1067\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m-> 1071\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1074\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1075\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1078\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1079\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pass the LLM, the tool (only one here) and the system prompt\n",
    "game = Game()  \n",
    "game_tool = GuessTool(game)\n",
    "discuss_tool = DiscussTool()\n",
    "refrain_tool = RefrainTool()\n",
    "abot = Agent(models, team_size=2, game=game, tools=[game_tool, discuss_tool, refrain_tool])\n",
    "messages = [HumanMessage(content=\"Play a game of Codenames.\")]\n",
    "result = abot.graph.invoke({\"messages\": messages}, {\"recursion_limit\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
