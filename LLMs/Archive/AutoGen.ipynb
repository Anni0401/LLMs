{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API Key loaded successfully\n",
      "Tavily API Key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if os.getenv(\"GROQ_API_KEY\"):\n",
    "    print('Groq API Key loaded successfully')\n",
    "else:\n",
    "    print('Groq API Key loading failed, please make sure the .env file exists and the spelling is correct')\n",
    "\n",
    "if os.getenv(\"TAVILY_API_KEY\"):\n",
    "    print('Tavily API Key loaded successfully')\n",
    "else:\n",
    "    print('Tavily API Key loading failed, please make sure the .env file exists and the spelling is correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import httpx\n",
    "import os\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "\n",
    "chat_model = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Autogen components\n",
    "from autogen import AssistantAgent, UserProxyAgent,  ConversableAgent,register_function\n",
    "from typing import TypedDict, List, Annotated\n",
    "import operator\n",
    "from typing import TypedDict, List, Tuple\n",
    "import operator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"model\": \"llama-3.1-70b-versatile\", \"api_key\": os.getenv(\"GROQ_API_KEY\"), \"api_type\": \"groq\"}\n",
    "assistant = ConversableAgent(\"chatbot\", llm_config=llm_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "{'content': 'A man walked into a library and asked the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replied, \"It rings a bell, but I\\'m not sure if it\\'s here or not.\"', 'refusal': None, 'role': 'assistant', 'audio': None, 'function_call': None, 'tool_calls': None}\n"
     ]
    }
   ],
   "source": [
    "reply = assistant.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "player_config_list = [\n",
    "    {\n",
    "        \"model\": \"llama-3.1-70b-versatile\",\n",
    "        \"api_key\": os.environ.get(\"GROQ_API_KEY\"),\n",
    "        \"api_type\": \"groq\"\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_red = ConversableAgent(\n",
    "    name=\"Player Red\",\n",
    "    system_message=\"You are a code names player. \"\n",
    "    \"First call get_grid() first, to get list of words of your team. \"\n",
    "    \"Then call make_move(move) to make a move.\",\n",
    "    llm_config={\"config_list\": player_config_list, \"cache_seed\": None},\n",
    ")\n",
    "\n",
    "player_blue = ConversableAgent(\n",
    "    name=\"Player Blue\",\n",
    "    system_message=\"You are a code names player. \"\n",
    "    \"First call get_grid() first, to get list of words of your team. \"\n",
    "    \"Then call make_move(move) to make a move.\",\n",
    "    llm_config={\"config_list\": player_config_list, \"cache_seed\": None},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid()-> Annotated[str, \"A list of words for associated team on the grid\"]:\n",
    "  \n",
    "    return  \"default\"\n",
    "\n",
    "def make_move(move: Annotated[str, \"A move in form of a word,int pair for the team to guess.\"]) -> Annotated[str, \"Result of the move.\"]:\n",
    "    return \" words to uncover in grid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_made_move(msg):\n",
    "    global made_move\n",
    "    if made_move:\n",
    "        made_move = False\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "grid_proxy = ConversableAgent(\n",
    "    name=\"Board Proxy\",\n",
    "    llm_config=False,\n",
    "    # The board proxy will only terminate the conversation if the player has made a move.\n",
    "    is_termination_msg=check_made_move,\n",
    "    # The auto reply message is set to keep the player agent retrying until a move is made.\n",
    "    default_auto_reply=\"Please make a move.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/autogen/agentchat/conversable_agent.py:2504: UserWarning: Function 'make_move' is being overridden.\n",
      "  warnings.warn(f\"Function '{name}' is being overridden.\", UserWarning)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/autogen/agentchat/conversable_agent.py:2504: UserWarning: Function 'get_grid' is being overridden.\n",
      "  warnings.warn(f\"Function '{name}' is being overridden.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "register_function(\n",
    "    make_move,\n",
    "    caller=player_red,\n",
    "    executor=grid_proxy,\n",
    "    name=\"make_move\",\n",
    "    description=\"Call this tool to make a move.\",\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    get_grid,\n",
    "    caller=player_red,\n",
    "    executor=grid_proxy,\n",
    "    name=\"get_grid\",\n",
    "    description=\"Get grid and words for each team.\",\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    make_move,\n",
    "    caller=player_blue,\n",
    "    executor=grid_proxy,\n",
    "    name=\"make_move\",\n",
    "    description=\"Call this tool to make a move.\",\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    get_grid,\n",
    "    caller=player_blue,\n",
    "    executor=grid_proxy,\n",
    "    name=\"get_grid\",\n",
    "    description=\"Get grid and words for each team.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config={\"config_list\": player_config_list, \"cache_seed\": 42}\n",
    "\n",
    "member1 = ConversableAgent(\n",
    "    name=\"Team member1\",\n",
    "    system_message=\"Short in answer.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "member2 = ConversableAgent(\n",
    "    name=\"Team member2\",\n",
    "    system_message=\"Creative but short in answer.\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import GroupChatManager, GroupChat\n",
    "\n",
    "groupchat = GroupChat(agents=[  member1, member2], messages=[], max_round=3, speaker_selection_method='round_robin',  # Ensures turn-taking\n",
    "    allow_repeat_speaker=False )\n",
    "manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mInit\u001b[0m (to chat_manager):\n",
      "\n",
      "find the words on the given grid given the clue by your spymaster.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Team member1\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mTeam member1\u001b[0m (to chat_manager):\n",
      "\n",
      "I'd be happy to help you find the words on the grid. However, I need a few more details. \n",
      "\n",
      "Please provide me with the following:\n",
      "\n",
      "1. The grid itself: I need the letters on the grid to be able to help you.\n",
      "2. The clue from your spymaster: I need to know what the clue is so I can give you accurate answers.\n",
      "3. Any other specific instructions or context: Are there any specific rules or constraints I should be aware of?\n",
      "\n",
      "Once I have this information, I'll do my best to help you find the words on the grid.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Team member2\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mTeam member2\u001b[0m (to chat_manager):\n",
      "\n",
      "Here's the grid and other details:\n",
      "\n",
      "Grid:\n",
      "A E H L N\n",
      "O I M R T\n",
      "S D F G Y\n",
      "B C J K U\n",
      "M P Q V W\n",
      "X Z  -  (there's an empty space on the grid)\n",
      "\n",
      "Clue from the Spymaster: \n",
      "Find the words hidden in the grid related to \"Music\".\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_message=\"find the words on the given grid given the clue by your spymaster.\"\n",
    "\n",
    "initializer = UserProxyAgent(\n",
    "    name=\"Init\",\n",
    ")\n",
    "\n",
    "try:\n",
    "    initializer.initiate_chat(manager, message =initial_message)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during chat initiation: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
